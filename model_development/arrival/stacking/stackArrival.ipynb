{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS DATA\n",
    "1) Train LightGBM  \n",
    "1.1) gridsearch  \n",
    "1.2) use the best params then do k fold ? then out of fold predictions save them  \n",
    "2) Train XGBoost   \n",
    "2.1) gridsearch   \n",
    "2.2) use the best params then do k fold? then out of fold predictions save them \n",
    "3) Train CatBoost  \n",
    "3.1) gridsearch  \n",
    "3.2) use the best params then do k fold? then out of fold predictions save them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score \n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd optiosn to read all columns \n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline Code</th>\n",
       "      <th>Aircraft Registration</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Type Code</th>\n",
       "      <th>Mode S</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>Age(years)</th>\n",
       "      <th>FROM</th>\n",
       "      <th>TO</th>\n",
       "      <th>Arrival_Delayed</th>\n",
       "      <th>STD_temp_scaled</th>\n",
       "      <th>STD_dwpt_scaled</th>\n",
       "      <th>STD_rhum_scaled</th>\n",
       "      <th>STD_prcp_scaled</th>\n",
       "      <th>STD_snow_scaled</th>\n",
       "      <th>STD_wdir_scaled</th>\n",
       "      <th>STD_wspd_scaled</th>\n",
       "      <th>STD_wpgt_scaled</th>\n",
       "      <th>STD_pres_scaled</th>\n",
       "      <th>STD_tsun_scaled</th>\n",
       "      <th>STD_coco_scaled</th>\n",
       "      <th>STA_temp_scaled</th>\n",
       "      <th>STA_dwpt_scaled</th>\n",
       "      <th>STA_rhum_scaled</th>\n",
       "      <th>STA_prcp_scaled</th>\n",
       "      <th>STA_snow_scaled</th>\n",
       "      <th>STA_wdir_scaled</th>\n",
       "      <th>STA_wspd_scaled</th>\n",
       "      <th>STA_wpgt_scaled</th>\n",
       "      <th>STA_pres_scaled</th>\n",
       "      <th>STA_tsun_scaled</th>\n",
       "      <th>STA_coco_scaled</th>\n",
       "      <th>STD_UTC_time_of_day_cosine</th>\n",
       "      <th>STD_UTC_time_of_year_cosine</th>\n",
       "      <th>STD_UTC_day_of_year</th>\n",
       "      <th>STD_UTC_week_of_year</th>\n",
       "      <th>STD_UTC_weekday</th>\n",
       "      <th>STD_UTC_hour_of_day</th>\n",
       "      <th>STA_UTC_time_of_day_cosine</th>\n",
       "      <th>STA_UTC_time_of_year_cosine</th>\n",
       "      <th>STA_UTC_day_of_year</th>\n",
       "      <th>STA_UTC_week_of_year</th>\n",
       "      <th>STA_UTC_weekday</th>\n",
       "      <th>STA_UTC_hour_of_day</th>\n",
       "      <th>final_pred_dep</th>\n",
       "      <th>Y_arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3u-csc</td>\n",
       "      <td>b-30cr</td>\n",
       "      <td>Sichuan Airlines</td>\n",
       "      <td>A20N</td>\n",
       "      <td>781848</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>YIN</td>\n",
       "      <td>TFU</td>\n",
       "      <td>True</td>\n",
       "      <td>0.605435</td>\n",
       "      <td>0.672010</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.861596</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555570</td>\n",
       "      <td>-0.492533</td>\n",
       "      <td>244</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>-0.492533</td>\n",
       "      <td>244.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3u-csc</td>\n",
       "      <td>b-30cr</td>\n",
       "      <td>Sichuan Airlines</td>\n",
       "      <td>A20N</td>\n",
       "      <td>781848</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TFU</td>\n",
       "      <td>YIN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.863132</td>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613830</td>\n",
       "      <td>0.668329</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625923</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.492533</td>\n",
       "      <td>244.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3u-csc</td>\n",
       "      <td>b-30cr</td>\n",
       "      <td>Sichuan Airlines</td>\n",
       "      <td>A20N</td>\n",
       "      <td>781848</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>URC</td>\n",
       "      <td>TFU</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.727497</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.087156</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.362438</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3u-csc</td>\n",
       "      <td>b-30cr</td>\n",
       "      <td>Sichuan Airlines</td>\n",
       "      <td>A20N</td>\n",
       "      <td>781848</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TFU</td>\n",
       "      <td>URC</td>\n",
       "      <td>False</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.852035</td>\n",
       "      <td>0.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.724439</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675590</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3u-csc</td>\n",
       "      <td>b-30cr</td>\n",
       "      <td>Sichuan Airlines</td>\n",
       "      <td>A20N</td>\n",
       "      <td>781848</td>\n",
       "      <td>8873.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ZHA</td>\n",
       "      <td>TFU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>0.898890</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>-0.522178</td>\n",
       "      <td>242</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.854912</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>243.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669782</th>\n",
       "      <td>SQ-SIA</td>\n",
       "      <td>9V-SDA</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>B78X</td>\n",
       "      <td>76CC81</td>\n",
       "      <td>67157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NGO</td>\n",
       "      <td>SIN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.789149</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>-0.084835</td>\n",
       "      <td>269</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>-0.084835</td>\n",
       "      <td>269.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669783</th>\n",
       "      <td>SQ-SIA</td>\n",
       "      <td>9V-SDA</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>B78X</td>\n",
       "      <td>76CC81</td>\n",
       "      <td>67157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>NGO</td>\n",
       "      <td>True</td>\n",
       "      <td>0.710870</td>\n",
       "      <td>0.868064</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.774314</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.101962</td>\n",
       "      <td>268</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.237686</td>\n",
       "      <td>-0.101962</td>\n",
       "      <td>268.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669784</th>\n",
       "      <td>SQ-SIA</td>\n",
       "      <td>9V-SDA</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>B78X</td>\n",
       "      <td>76CC81</td>\n",
       "      <td>67157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>CHS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.627174</td>\n",
       "      <td>0.755857</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.761845</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.923880</td>\n",
       "      <td>-0.336289</td>\n",
       "      <td>254</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.928810</td>\n",
       "      <td>-0.336289</td>\n",
       "      <td>254.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669785</th>\n",
       "      <td>SQ-SIA</td>\n",
       "      <td>9V-SDA</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>B78X</td>\n",
       "      <td>76CC81</td>\n",
       "      <td>67157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>CHS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.833539</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.054852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.555570</td>\n",
       "      <td>-0.477489</td>\n",
       "      <td>245</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.492424</td>\n",
       "      <td>-0.477489</td>\n",
       "      <td>245.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669786</th>\n",
       "      <td>SQ-SIA</td>\n",
       "      <td>9V-SDA</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>B78X</td>\n",
       "      <td>76CC81</td>\n",
       "      <td>67157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>CHS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.693478</td>\n",
       "      <td>0.860666</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.711702</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.032068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.659346</td>\n",
       "      <td>-0.492533</td>\n",
       "      <td>244</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.900698</td>\n",
       "      <td>-0.492533</td>\n",
       "      <td>244.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11669787 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Airline Code Aircraft Registration            Operator Type Code  \\\n",
       "0              3u-csc                b-30cr    Sichuan Airlines      A20N   \n",
       "1              3u-csc                b-30cr    Sichuan Airlines      A20N   \n",
       "2              3u-csc                b-30cr    Sichuan Airlines      A20N   \n",
       "3              3u-csc                b-30cr    Sichuan Airlines      A20N   \n",
       "4              3u-csc                b-30cr    Sichuan Airlines      A20N   \n",
       "...               ...                   ...                 ...       ...   \n",
       "11669782       SQ-SIA               9V-SDA   Singapore Airlines      B78X   \n",
       "11669783       SQ-SIA               9V-SDA   Singapore Airlines      B78X   \n",
       "11669784       SQ-SIA               9V-SDA   Singapore Airlines      B78X   \n",
       "11669785       SQ-SIA               9V-SDA   Singapore Airlines      B78X   \n",
       "11669786       SQ-SIA               9V-SDA   Singapore Airlines      B78X   \n",
       "\n",
       "          Mode S Serial Number  Age(years) FROM   TO  Arrival_Delayed  \\\n",
       "0         781848        8873.0         5.0  YIN  TFU             True   \n",
       "1         781848        8873.0         5.0  TFU  YIN            False   \n",
       "2         781848        8873.0         5.0  URC  TFU             True   \n",
       "3         781848        8873.0         5.0  TFU  URC            False   \n",
       "4         781848        8873.0         5.0  ZHA  TFU            False   \n",
       "...          ...           ...         ...  ...  ...              ...   \n",
       "11669782  76CC81       67157.0         0.0  NGO  SIN            False   \n",
       "11669783  76CC81       67157.0         0.0  CHS  NGO             True   \n",
       "11669784  76CC81       67157.0         0.0  CHS  CHS             True   \n",
       "11669785  76CC81       67157.0         0.0  CHS  CHS             True   \n",
       "11669786  76CC81       67157.0         0.0  CHS  CHS             True   \n",
       "\n",
       "          STD_temp_scaled  STD_dwpt_scaled  STD_rhum_scaled  STD_prcp_scaled  \\\n",
       "0                0.605435         0.672010             0.62              NaN   \n",
       "1                0.739130         0.863132             0.79              NaN   \n",
       "2                0.652174         0.727497             0.64              NaN   \n",
       "3                0.782609         0.852035             0.59              NaN   \n",
       "4                0.744565         0.898890             0.91              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "11669782         0.717391         0.789149             0.61              0.0   \n",
       "11669783         0.710870         0.868064             0.94              0.0   \n",
       "11669784         0.627174         0.755857             0.86              0.0   \n",
       "11669785         0.790217         0.833539             0.52              0.0   \n",
       "11669786         0.693478         0.860666             1.00              0.0   \n",
       "\n",
       "          STD_snow_scaled  STD_wdir_scaled  STD_wspd_scaled  STD_wpgt_scaled  \\\n",
       "0                     NaN         0.125000           0.0360              NaN   \n",
       "1                     NaN         0.055556           0.0432              NaN   \n",
       "2                     NaN         0.530556           0.0144              NaN   \n",
       "3                     NaN         0.083333           0.0576              NaN   \n",
       "4                     NaN         0.166667           0.0288              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "11669782              NaN         0.777778           0.0520              NaN   \n",
       "11669783              NaN         0.416667           0.0376              NaN   \n",
       "11669784              NaN         0.027778           0.0448              NaN   \n",
       "11669785              NaN         0.472222           0.0520              NaN   \n",
       "11669786              NaN         1.000000           0.0304              NaN   \n",
       "\n",
       "          STD_pres_scaled  STD_tsun_scaled  STD_coco_scaled  STA_temp_scaled  \\\n",
       "0                0.677922              NaN              NaN         0.776596   \n",
       "1                     NaN              NaN              NaN         0.613830   \n",
       "2                0.688312              NaN              NaN         0.755319   \n",
       "3                     NaN              NaN              NaN         0.712766   \n",
       "4                0.612338              NaN             0.28         0.787234   \n",
       "...                   ...              ...              ...              ...   \n",
       "11669782         0.655844              NaN             0.08         0.787234   \n",
       "11669783         0.655195              NaN             0.04         0.680851   \n",
       "11669784         0.685714              NaN             0.04         0.670213   \n",
       "11669785         0.673377              NaN             0.28         0.794681   \n",
       "11669786         0.681818              NaN             0.24         0.711702   \n",
       "\n",
       "          STA_dwpt_scaled  STA_rhum_scaled  STA_prcp_scaled  STA_snow_scaled  \\\n",
       "0                0.861596             0.66              NaN              NaN   \n",
       "1                0.668329             0.62              NaN              NaN   \n",
       "2                0.860349             0.74              NaN              NaN   \n",
       "3                0.724439             0.47              NaN              NaN   \n",
       "4                0.862843             0.63              NaN              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "11669782         0.887781             0.71              0.0              NaN   \n",
       "11669783         0.774314             0.73              0.0              NaN   \n",
       "11669784         0.761845             0.73              0.0              NaN   \n",
       "11669785         0.831671             0.52              0.0              NaN   \n",
       "11669786         0.864090             0.96              0.0              NaN   \n",
       "\n",
       "          STA_wdir_scaled  STA_wspd_scaled  STA_wpgt_scaled  STA_pres_scaled  \\\n",
       "0                1.000000         0.045570              NaN         0.590314   \n",
       "1                0.125000         0.037975              NaN         0.683246   \n",
       "2                1.000000         0.045570              NaN              NaN   \n",
       "3                0.944444         0.045570              NaN              NaN   \n",
       "4                0.111111         0.060759              NaN              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "11669782         0.333333         0.047257              NaN         0.646597   \n",
       "11669783         0.138889         0.054852              NaN         0.667539   \n",
       "11669784         0.083333         0.054852              NaN         0.695026   \n",
       "11669785         0.472222         0.054852              NaN         0.678665   \n",
       "11669786         0.055556         0.032068              NaN         0.689136   \n",
       "\n",
       "          STA_tsun_scaled  STA_coco_scaled  STD_UTC_time_of_day_cosine  \\\n",
       "0                     NaN              NaN                    0.555570   \n",
       "1                     NaN              NaN                    0.625923   \n",
       "2                     NaN              NaN                   -0.087156   \n",
       "3                     NaN              NaN                    0.675590   \n",
       "4                     NaN              NaN                    0.999762   \n",
       "...                   ...              ...                         ...   \n",
       "11669782              NaN             0.08                    0.793353   \n",
       "11669783              NaN             0.08                    0.258819   \n",
       "11669784              NaN             0.04                   -0.923880   \n",
       "11669785              NaN             0.28                   -0.555570   \n",
       "11669786              NaN             0.24                   -0.659346   \n",
       "\n",
       "          STD_UTC_time_of_year_cosine  STD_UTC_day_of_year  \\\n",
       "0                           -0.492533                  244   \n",
       "1                           -0.507430                  243   \n",
       "2                           -0.507430                  243   \n",
       "3                           -0.507430                  243   \n",
       "4                           -0.522178                  242   \n",
       "...                               ...                  ...   \n",
       "11669782                    -0.084835                  269   \n",
       "11669783                    -0.101962                  268   \n",
       "11669784                    -0.336289                  254   \n",
       "11669785                    -0.477489                  245   \n",
       "11669786                    -0.492533                  244   \n",
       "\n",
       "          STD_UTC_week_of_year  STD_UTC_weekday  STD_UTC_hour_of_day  \\\n",
       "0                           35                5                    3   \n",
       "1                           35                4                   20   \n",
       "2                           35                4                   17   \n",
       "3                           35                4                    3   \n",
       "4                           35                3                   23   \n",
       "...                        ...              ...                  ...   \n",
       "11669782                    39                2                    2   \n",
       "11669783                    39                1                    5   \n",
       "11669784                    37                1                   10   \n",
       "11669785                    35                6                   15   \n",
       "11669786                    35                5                    8   \n",
       "\n",
       "          STA_UTC_time_of_day_cosine  STA_UTC_time_of_year_cosine  \\\n",
       "0                           0.021815                    -0.492533   \n",
       "1                           0.707107                    -0.492533   \n",
       "2                           0.362438                    -0.507430   \n",
       "3                          -0.642788                    -0.507430   \n",
       "4                           0.854912                    -0.507430   \n",
       "...                              ...                          ...   \n",
       "11669782                    0.793353                    -0.084835   \n",
       "11669783                    0.237686                    -0.101962   \n",
       "11669784                   -0.928810                    -0.336289   \n",
       "11669785                   -0.492424                    -0.477489   \n",
       "11669786                   -0.900698                    -0.492533   \n",
       "\n",
       "          STA_UTC_day_of_year  STA_UTC_week_of_year  STA_UTC_weekday  \\\n",
       "0                       244.0                  35.0              5.0   \n",
       "1                       244.0                  35.0              5.0   \n",
       "2                       243.0                  35.0              4.0   \n",
       "3                       243.0                  35.0              4.0   \n",
       "4                       243.0                  35.0              4.0   \n",
       "...                       ...                   ...              ...   \n",
       "11669782                269.0                  39.0              2.0   \n",
       "11669783                268.0                  39.0              1.0   \n",
       "11669784                254.0                  37.0              1.0   \n",
       "11669785                245.0                  35.0              6.0   \n",
       "11669786                244.0                  35.0              5.0   \n",
       "\n",
       "          STA_UTC_hour_of_day  final_pred_dep  Y_arrival  \n",
       "0                         5.0               1       True  \n",
       "1                         3.0               1      False  \n",
       "2                        19.0               1       True  \n",
       "3                         8.0               1      False  \n",
       "4                         2.0               1      False  \n",
       "...                       ...             ...        ...  \n",
       "11669782                  2.0               1      False  \n",
       "11669783                 18.0               1       True  \n",
       "11669784                 13.0               1       True  \n",
       "11669785                 16.0               1       True  \n",
       "11669786                 10.0               1       True  \n",
       "\n",
       "[11669787 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('CLEANED_V9.parquet') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Arrival_Delayed']  # target variable \n",
    "\n",
    "# drop columns that are not needed\n",
    "columns_to_drop = [col for col in df.columns if col.startswith('ATA') or col.startswith('ATD') or col == 'Arrival_Delayed']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "#duplicated column of arrival_delayed \n",
    "X = df.drop(columns=['Y_arrival']) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airline Code', 'Aircraft Registration', 'Operator', 'Type Code',\n",
       "       'Mode S', 'Serial Number', 'Age(years)', 'FROM', 'TO',\n",
       "       'STD_temp_scaled', 'STD_dwpt_scaled', 'STD_rhum_scaled',\n",
       "       'STD_prcp_scaled', 'STD_snow_scaled', 'STD_wdir_scaled',\n",
       "       'STD_wspd_scaled', 'STD_wpgt_scaled', 'STD_pres_scaled',\n",
       "       'STD_tsun_scaled', 'STD_coco_scaled', 'STA_temp_scaled',\n",
       "       'STA_dwpt_scaled', 'STA_rhum_scaled', 'STA_prcp_scaled',\n",
       "       'STA_snow_scaled', 'STA_wdir_scaled', 'STA_wspd_scaled',\n",
       "       'STA_wpgt_scaled', 'STA_pres_scaled', 'STA_tsun_scaled',\n",
       "       'STA_coco_scaled', 'STD_UTC_time_of_day_cosine',\n",
       "       'STD_UTC_time_of_year_cosine', 'STD_UTC_day_of_year',\n",
       "       'STD_UTC_week_of_year', 'STD_UTC_weekday', 'STD_UTC_hour_of_day',\n",
       "       'STA_UTC_time_of_day_cosine', 'STA_UTC_time_of_year_cosine',\n",
       "       'STA_UTC_day_of_year', 'STA_UTC_week_of_year', 'STA_UTC_weekday',\n",
       "       'STA_UTC_hour_of_day', 'final_pred_dep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Code                   category\n",
      "Aircraft Registration          category\n",
      "Operator                       category\n",
      "Type Code                      category\n",
      "Mode S                         category\n",
      "Serial Number                  category\n",
      "Age(years)                      float32\n",
      "FROM                           category\n",
      "TO                             category\n",
      "STD_temp_scaled                 float64\n",
      "STD_dwpt_scaled                 float64\n",
      "STD_rhum_scaled                 float64\n",
      "STD_prcp_scaled                 float64\n",
      "STD_snow_scaled                 float64\n",
      "STD_wdir_scaled                 float64\n",
      "STD_wspd_scaled                 float64\n",
      "STD_wpgt_scaled                 float64\n",
      "STD_pres_scaled                 float64\n",
      "STD_tsun_scaled                 float64\n",
      "STD_coco_scaled                 float64\n",
      "STA_temp_scaled                 float64\n",
      "STA_dwpt_scaled                 float64\n",
      "STA_rhum_scaled                 float64\n",
      "STA_prcp_scaled                 float64\n",
      "STA_snow_scaled                 float64\n",
      "STA_wdir_scaled                 float64\n",
      "STA_wspd_scaled                 float64\n",
      "STA_wpgt_scaled                 float64\n",
      "STA_pres_scaled                 float64\n",
      "STA_tsun_scaled                 float64\n",
      "STA_coco_scaled                 float64\n",
      "STD_UTC_time_of_day_cosine      float64\n",
      "STD_UTC_time_of_year_cosine     float64\n",
      "STD_UTC_day_of_year               int64\n",
      "STD_UTC_week_of_year              int64\n",
      "STD_UTC_weekday                   int64\n",
      "STD_UTC_hour_of_day               int64\n",
      "STA_UTC_time_of_day_cosine      float64\n",
      "STA_UTC_time_of_year_cosine     float64\n",
      "STA_UTC_day_of_year             float64\n",
      "STA_UTC_week_of_year            float64\n",
      "STA_UTC_weekday                 float64\n",
      "STA_UTC_hour_of_day             float64\n",
      "final_pred_dep                     int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (X.dtypes)\n",
    "\n",
    "# Convert all float64 columns to float32\n",
    "float_cols = X.select_dtypes(include=['float64']).columns\n",
    "X[float_cols] = X[float_cols].astype(np.float32)\n",
    "\n",
    "# Convert all int64 columns to int32 (if range is small enough)\n",
    "int_cols = X.select_dtypes(include=['int64']).columns\n",
    "X[int_cols] = X[int_cols].astype(np.int32)\n",
    "\n",
    "# Convert categorical variables to category dtype\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "X[cat_cols] = X[cat_cols].astype('category')\n",
    "\n",
    "\n",
    "# Handle missing values in categorical columns by adding \"Missing\" as a valid category\n",
    "for col in cat_cols:\n",
    "    X[col] = X[col].cat.add_categories(\"Missing\")\n",
    "    X[col] = X[col].fillna(\"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline Code                   category\n",
       "Aircraft Registration          category\n",
       "Operator                       category\n",
       "Type Code                      category\n",
       "Mode S                         category\n",
       "Serial Number                  category\n",
       "Age(years)                      float32\n",
       "FROM                           category\n",
       "TO                             category\n",
       "STD_temp_scaled                 float32\n",
       "STD_dwpt_scaled                 float32\n",
       "STD_rhum_scaled                 float32\n",
       "STD_prcp_scaled                 float32\n",
       "STD_snow_scaled                 float32\n",
       "STD_wdir_scaled                 float32\n",
       "STD_wspd_scaled                 float32\n",
       "STD_wpgt_scaled                 float32\n",
       "STD_pres_scaled                 float32\n",
       "STD_tsun_scaled                 float32\n",
       "STD_coco_scaled                 float32\n",
       "STA_temp_scaled                 float32\n",
       "STA_dwpt_scaled                 float32\n",
       "STA_rhum_scaled                 float32\n",
       "STA_prcp_scaled                 float32\n",
       "STA_snow_scaled                 float32\n",
       "STA_wdir_scaled                 float32\n",
       "STA_wspd_scaled                 float32\n",
       "STA_wpgt_scaled                 float32\n",
       "STA_pres_scaled                 float32\n",
       "STA_tsun_scaled                 float32\n",
       "STA_coco_scaled                 float32\n",
       "STD_UTC_time_of_day_cosine      float32\n",
       "STD_UTC_time_of_year_cosine     float32\n",
       "STD_UTC_day_of_year               int32\n",
       "STD_UTC_week_of_year              int32\n",
       "STD_UTC_weekday                   int32\n",
       "STD_UTC_hour_of_day               int32\n",
       "STA_UTC_time_of_day_cosine      float32\n",
       "STA_UTC_time_of_year_cosine     float32\n",
       "STA_UTC_day_of_year             float32\n",
       "STA_UTC_week_of_year            float32\n",
       "STA_UTC_weekday                 float32\n",
       "STA_UTC_hour_of_day             float32\n",
       "final_pred_dep                     int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING FOR UNIQUE VALUES BEFORE I RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Code: 78 unique values\n",
      "Aircraft Registration: 9745 unique values\n",
      "Operator: 113 unique values\n",
      "Type Code: 64 unique values\n",
      "Mode S: 9560 unique values\n",
      "Serial Number: 9404 unique values\n",
      "FROM: 1876 unique values\n",
      "TO: 1847 unique values\n",
      "Age(years): 36 unique values\n",
      "STD_temp_scaled: 855 unique values\n",
      "STD_dwpt_scaled: 731 unique values\n",
      "STD_rhum_scaled: 100 unique values\n",
      "STD_prcp_scaled: 323 unique values\n",
      "STD_snow_scaled: 53 unique values\n",
      "STD_wdir_scaled: 361 unique values\n",
      "STD_wspd_scaled: 289 unique values\n",
      "STD_wpgt_scaled: 352 unique values\n",
      "STD_pres_scaled: 909 unique values\n",
      "STD_tsun_scaled: 61 unique values\n",
      "STD_coco_scaled: 25 unique values\n",
      "STA_temp_scaled: 857 unique values\n",
      "STA_dwpt_scaled: 725 unique values\n",
      "STA_rhum_scaled: 101 unique values\n",
      "STA_prcp_scaled: 320 unique values\n",
      "STA_snow_scaled: 60 unique values\n",
      "STA_wdir_scaled: 361 unique values\n",
      "STA_wspd_scaled: 301 unique values\n",
      "STA_wpgt_scaled: 353 unique values\n",
      "STA_pres_scaled: 913 unique values\n",
      "STA_tsun_scaled: 61 unique values\n",
      "STA_coco_scaled: 25 unique values\n",
      "STD_UTC_time_of_day_cosine: 722 unique values\n",
      "STD_UTC_time_of_year_cosine: 366 unique values\n",
      "STA_UTC_time_of_day_cosine: 722 unique values\n",
      "STA_UTC_time_of_year_cosine: 366 unique values\n",
      "STA_UTC_day_of_year: 366 unique values\n",
      "STA_UTC_week_of_year: 52 unique values\n",
      "STA_UTC_weekday: 7 unique values\n",
      "STA_UTC_hour_of_day: 24 unique values\n"
     ]
    }
   ],
   "source": [
    "# Check categorical columns\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {X_train[col].nunique()} unique values\")\n",
    "\n",
    "# Check numerical columns\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'float32']).columns\n",
    "for col in num_cols:\n",
    "    print(f\"{col}: {X_train[col].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRID SEARCH FOR LGB (SKIP THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'device': 'cpu',\n",
    "    'verbosity': 1,\n",
    "    'max_bin': 255,       # A reasonable bin size for CPU\n",
    "    'n_jobs': 16          # Use all 16 threads in LightGBM\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "lgb_grid = {\n",
    "    'num_leaves': [31, ],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'n_estimators': [10, 20]\n",
    "}\n",
    "# If your dataset is large, you might reduce cv=3 or cv=5 to manage runtime.\n",
    "# For parallel hyperparameter searches, you can set n_jobs=4 or 8 in GridSearchCV.\n",
    "# Using all 16 can be very heavy if each fold also tries to use multiple threads.\n",
    "lgb_gs = GridSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(**lgb_params),\n",
    "    param_grid=lgb_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    n_jobs=4  # parallel jobs for hyperparameter search\n",
    ")\n",
    "\n",
    "lgb_gs.fit(X_train, y_train)\n",
    "print(\"Best LightGBM Parameters:\", lgb_gs.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After GridSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2788518, number of negative: 4680145\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.468671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34158\n",
      "[LightGBM] [Info] Number of data points in the train set: 7468663, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373362 -> initscore=-0.517819\n",
      "[LightGBM] [Info] Start training from score -0.517819\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.521866\n",
      "Training fold 2/5...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2787869, number of negative: 4680794\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.403807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34186\n",
      "[LightGBM] [Info] Number of data points in the train set: 7468663, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373276 -> initscore=-0.518190\n",
      "[LightGBM] [Info] Start training from score -0.518190\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.521432\n",
      "Training fold 3/5...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2788224, number of negative: 4680439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34154\n",
      "[LightGBM] [Info] Number of data points in the train set: 7468663, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373323 -> initscore=-0.517987\n",
      "[LightGBM] [Info] Start training from score -0.517987\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.521025\n",
      "Training fold 4/5...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2788984, number of negative: 4679679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.452261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34178\n",
      "[LightGBM] [Info] Number of data points in the train set: 7468663, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373425 -> initscore=-0.517552\n",
      "[LightGBM] [Info] Start training from score -0.517552\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.521644\n",
      "Training fold 5/5...\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2788697, number of negative: 4679967\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.465752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34191\n",
      "[LightGBM] [Info] Number of data points in the train set: 7468664, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373386 -> initscore=-0.517717\n",
      "[LightGBM] [Info] Start training from score -0.517717\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.5222\n",
      "OOF Accuracy: 0.7384\n",
      "Test Accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "lgb_bestParams = {\n",
    "    'num_leaves': 255,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 300\n",
    "} \n",
    "\n",
    "#  Number of folds\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#  Storage for OOF predictions\n",
    "oof_preds_lgb = np.zeros(X_train.shape[0]) \n",
    "test_preds_lgb = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold+1}/{n_folds}...\")\n",
    "\n",
    "    #  Split data\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    #  Train LightGBM model with best parameters\n",
    "    model = lgb.LGBMClassifier(**lgb_bestParams)\n",
    "    model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],  #  Validation set\n",
    "    eval_metric=\"logloss\",  #  Add evaluation metric\n",
    "    callbacks=[lgb.early_stopping(10,verbose=True)]\n",
    "    )\n",
    "\n",
    "    #  Predict OOF for this fold\n",
    "    oof_preds_lgb[valid_idx] = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    #  Predict test set (average across folds)\n",
    "    test_preds_lgb += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "\n",
    "#  Compute final accuracy (on OOF predictions)\n",
    "oof_accuracy = accuracy_score(y_train, (oof_preds_lgb > 0.5).astype(int))\n",
    "\n",
    "\n",
    "#  Evaluate XGBoost Test Accuracy\n",
    "test_preds_lgb_binary = (test_preds_lgb > 0.5).astype(int)\n",
    "test_accuracy_lgb = accuracy_score(y_test, test_preds_lgb_binary)\n",
    "\n",
    "\n",
    "print(f\"OOF Accuracy: {oof_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_lgb:.4f}\") \n",
    "\n",
    "#* Now `oof_preds` and `test_preds` are ready for stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST  \n",
    "GRID SEARCH WITH XGBOOST (Not Performed In this script) - task separated out for another team, but  the following params are used based on the best params found by them on gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET MY RESULTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW I TRAIN XGBOOST WITH K FOLD WITH BY RIGHT BEST PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:57:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64072\n",
      "[1]\tvalidation_0-logloss:0.62578\n",
      "[2]\tvalidation_0-logloss:0.61484\n",
      "[3]\tvalidation_0-logloss:0.60641\n",
      "[4]\tvalidation_0-logloss:0.60024\n",
      "[5]\tvalidation_0-logloss:0.59490\n",
      "[6]\tvalidation_0-logloss:0.59027\n",
      "[7]\tvalidation_0-logloss:0.58719\n",
      "[8]\tvalidation_0-logloss:0.58363\n",
      "[9]\tvalidation_0-logloss:0.58187\n",
      "[10]\tvalidation_0-logloss:0.57871\n",
      "[11]\tvalidation_0-logloss:0.57692\n",
      "[12]\tvalidation_0-logloss:0.57533\n",
      "[13]\tvalidation_0-logloss:0.57323\n",
      "[14]\tvalidation_0-logloss:0.57148\n",
      "[15]\tvalidation_0-logloss:0.56985\n",
      "[16]\tvalidation_0-logloss:0.56874\n",
      "[17]\tvalidation_0-logloss:0.56811\n",
      "[18]\tvalidation_0-logloss:0.56737\n",
      "[19]\tvalidation_0-logloss:0.56609\n",
      "[20]\tvalidation_0-logloss:0.56472\n",
      "[21]\tvalidation_0-logloss:0.56282\n",
      "[22]\tvalidation_0-logloss:0.56156\n",
      "[23]\tvalidation_0-logloss:0.56092\n",
      "[24]\tvalidation_0-logloss:0.55998\n",
      "[25]\tvalidation_0-logloss:0.55929\n",
      "[26]\tvalidation_0-logloss:0.55860\n",
      "[27]\tvalidation_0-logloss:0.55818\n",
      "[28]\tvalidation_0-logloss:0.55728\n",
      "[29]\tvalidation_0-logloss:0.55713\n",
      "[30]\tvalidation_0-logloss:0.55659\n",
      "[31]\tvalidation_0-logloss:0.55609\n",
      "[32]\tvalidation_0-logloss:0.55511\n",
      "[33]\tvalidation_0-logloss:0.55428\n",
      "[34]\tvalidation_0-logloss:0.55414\n",
      "[35]\tvalidation_0-logloss:0.55390\n",
      "[36]\tvalidation_0-logloss:0.55366\n",
      "[37]\tvalidation_0-logloss:0.55320\n",
      "[38]\tvalidation_0-logloss:0.55277\n",
      "[39]\tvalidation_0-logloss:0.55246\n",
      "[40]\tvalidation_0-logloss:0.55228\n",
      "[41]\tvalidation_0-logloss:0.55189\n",
      "[42]\tvalidation_0-logloss:0.55130\n",
      "[43]\tvalidation_0-logloss:0.55102\n",
      "[44]\tvalidation_0-logloss:0.55009\n",
      "[45]\tvalidation_0-logloss:0.55001\n",
      "[46]\tvalidation_0-logloss:0.54991\n",
      "[47]\tvalidation_0-logloss:0.54918\n",
      "[48]\tvalidation_0-logloss:0.54906\n",
      "[49]\tvalidation_0-logloss:0.54897\n",
      "[50]\tvalidation_0-logloss:0.54881\n",
      "[51]\tvalidation_0-logloss:0.54869\n",
      "[52]\tvalidation_0-logloss:0.54836\n",
      "[53]\tvalidation_0-logloss:0.54825\n",
      "[54]\tvalidation_0-logloss:0.54821\n",
      "[55]\tvalidation_0-logloss:0.54803\n",
      "[56]\tvalidation_0-logloss:0.54795\n",
      "[57]\tvalidation_0-logloss:0.54783\n",
      "[58]\tvalidation_0-logloss:0.54779\n",
      "[59]\tvalidation_0-logloss:0.54693\n",
      "[60]\tvalidation_0-logloss:0.54673\n",
      "[61]\tvalidation_0-logloss:0.54627\n",
      "[62]\tvalidation_0-logloss:0.54624\n",
      "[63]\tvalidation_0-logloss:0.54582\n",
      "[64]\tvalidation_0-logloss:0.54568\n",
      "[65]\tvalidation_0-logloss:0.54564\n",
      "[66]\tvalidation_0-logloss:0.54540\n",
      "[67]\tvalidation_0-logloss:0.54529\n",
      "[68]\tvalidation_0-logloss:0.54526\n",
      "[69]\tvalidation_0-logloss:0.54518\n",
      "[70]\tvalidation_0-logloss:0.54516\n",
      "[71]\tvalidation_0-logloss:0.54508\n",
      "[72]\tvalidation_0-logloss:0.54476\n",
      "[73]\tvalidation_0-logloss:0.54429\n",
      "[74]\tvalidation_0-logloss:0.54424\n",
      "[75]\tvalidation_0-logloss:0.54392\n",
      "[76]\tvalidation_0-logloss:0.54389\n",
      "[77]\tvalidation_0-logloss:0.54386\n",
      "[78]\tvalidation_0-logloss:0.54371\n",
      "[79]\tvalidation_0-logloss:0.54368\n",
      "[80]\tvalidation_0-logloss:0.54331\n",
      "[81]\tvalidation_0-logloss:0.54309\n",
      "[82]\tvalidation_0-logloss:0.54302\n",
      "[83]\tvalidation_0-logloss:0.54298\n",
      "[84]\tvalidation_0-logloss:0.54217\n",
      "[85]\tvalidation_0-logloss:0.54190\n",
      "[86]\tvalidation_0-logloss:0.54165\n",
      "[87]\tvalidation_0-logloss:0.54132\n",
      "[88]\tvalidation_0-logloss:0.54130\n",
      "[89]\tvalidation_0-logloss:0.54129\n",
      "[90]\tvalidation_0-logloss:0.54125\n",
      "[91]\tvalidation_0-logloss:0.54120\n",
      "[92]\tvalidation_0-logloss:0.54119\n",
      "[93]\tvalidation_0-logloss:0.54116\n",
      "[94]\tvalidation_0-logloss:0.54075\n",
      "[95]\tvalidation_0-logloss:0.54074\n",
      "[96]\tvalidation_0-logloss:0.54073\n",
      "[97]\tvalidation_0-logloss:0.54053\n",
      "[98]\tvalidation_0-logloss:0.54049\n",
      "[99]\tvalidation_0-logloss:0.54043\n",
      "[100]\tvalidation_0-logloss:0.54042\n",
      "[101]\tvalidation_0-logloss:0.54038\n",
      "[102]\tvalidation_0-logloss:0.53994\n",
      "[103]\tvalidation_0-logloss:0.53989\n",
      "[104]\tvalidation_0-logloss:0.53974\n",
      "[105]\tvalidation_0-logloss:0.53973\n",
      "[106]\tvalidation_0-logloss:0.53934\n",
      "[107]\tvalidation_0-logloss:0.53931\n",
      "[108]\tvalidation_0-logloss:0.53929\n",
      "[109]\tvalidation_0-logloss:0.53882\n",
      "[110]\tvalidation_0-logloss:0.53859\n",
      "[111]\tvalidation_0-logloss:0.53845\n",
      "[112]\tvalidation_0-logloss:0.53823\n",
      "[113]\tvalidation_0-logloss:0.53819\n",
      "[114]\tvalidation_0-logloss:0.53817\n",
      "[115]\tvalidation_0-logloss:0.53816\n",
      "[116]\tvalidation_0-logloss:0.53810\n",
      "[117]\tvalidation_0-logloss:0.53788\n",
      "[118]\tvalidation_0-logloss:0.53783\n",
      "[119]\tvalidation_0-logloss:0.53782\n",
      "[120]\tvalidation_0-logloss:0.53779\n",
      "[121]\tvalidation_0-logloss:0.53778\n",
      "[122]\tvalidation_0-logloss:0.53754\n",
      "[123]\tvalidation_0-logloss:0.53730\n",
      "[124]\tvalidation_0-logloss:0.53698\n",
      "[125]\tvalidation_0-logloss:0.53670\n",
      "[126]\tvalidation_0-logloss:0.53647\n",
      "[127]\tvalidation_0-logloss:0.53637\n",
      "[128]\tvalidation_0-logloss:0.53628\n",
      "[129]\tvalidation_0-logloss:0.53625\n",
      "[130]\tvalidation_0-logloss:0.53621\n",
      "[131]\tvalidation_0-logloss:0.53620\n",
      "[132]\tvalidation_0-logloss:0.53615\n",
      "[133]\tvalidation_0-logloss:0.53610\n",
      "[134]\tvalidation_0-logloss:0.53602\n",
      "[135]\tvalidation_0-logloss:0.53595\n",
      "[136]\tvalidation_0-logloss:0.53588\n",
      "[137]\tvalidation_0-logloss:0.53587\n",
      "[138]\tvalidation_0-logloss:0.53570\n",
      "[139]\tvalidation_0-logloss:0.53565\n",
      "[140]\tvalidation_0-logloss:0.53561\n",
      "[141]\tvalidation_0-logloss:0.53558\n",
      "[142]\tvalidation_0-logloss:0.53521\n",
      "[143]\tvalidation_0-logloss:0.53520\n",
      "[144]\tvalidation_0-logloss:0.53520\n",
      "[145]\tvalidation_0-logloss:0.53502\n",
      "[146]\tvalidation_0-logloss:0.53502\n",
      "[147]\tvalidation_0-logloss:0.53495\n",
      "[148]\tvalidation_0-logloss:0.53494\n",
      "[149]\tvalidation_0-logloss:0.53480\n",
      "[150]\tvalidation_0-logloss:0.53477\n",
      "[151]\tvalidation_0-logloss:0.53477\n",
      "[152]\tvalidation_0-logloss:0.53478\n",
      "[153]\tvalidation_0-logloss:0.53467\n",
      "[154]\tvalidation_0-logloss:0.53468\n",
      "[155]\tvalidation_0-logloss:0.53452\n",
      "[156]\tvalidation_0-logloss:0.53453\n",
      "[157]\tvalidation_0-logloss:0.53449\n",
      "[158]\tvalidation_0-logloss:0.53450\n",
      "[159]\tvalidation_0-logloss:0.53449\n",
      "[160]\tvalidation_0-logloss:0.53435\n",
      "[161]\tvalidation_0-logloss:0.53428\n",
      "[162]\tvalidation_0-logloss:0.53388\n",
      "[163]\tvalidation_0-logloss:0.53378\n",
      "[164]\tvalidation_0-logloss:0.53378\n",
      "[165]\tvalidation_0-logloss:0.53379\n",
      "[166]\tvalidation_0-logloss:0.53377\n",
      "[167]\tvalidation_0-logloss:0.53375\n",
      "[168]\tvalidation_0-logloss:0.53375\n",
      "[169]\tvalidation_0-logloss:0.53374\n",
      "[170]\tvalidation_0-logloss:0.53374\n",
      "[171]\tvalidation_0-logloss:0.53374\n",
      "[172]\tvalidation_0-logloss:0.53370\n",
      "[173]\tvalidation_0-logloss:0.53344\n",
      "[174]\tvalidation_0-logloss:0.53344\n",
      "[175]\tvalidation_0-logloss:0.53338\n",
      "[176]\tvalidation_0-logloss:0.53336\n",
      "[177]\tvalidation_0-logloss:0.53336\n",
      "[178]\tvalidation_0-logloss:0.53334\n",
      "[179]\tvalidation_0-logloss:0.53334\n",
      "[180]\tvalidation_0-logloss:0.53323\n",
      "[181]\tvalidation_0-logloss:0.53296\n",
      "[182]\tvalidation_0-logloss:0.53292\n",
      "[183]\tvalidation_0-logloss:0.53288\n",
      "[184]\tvalidation_0-logloss:0.53273\n",
      "[185]\tvalidation_0-logloss:0.53273\n",
      "[186]\tvalidation_0-logloss:0.53266\n",
      "[187]\tvalidation_0-logloss:0.53263\n",
      "[188]\tvalidation_0-logloss:0.53263\n",
      "[189]\tvalidation_0-logloss:0.53263\n",
      "[190]\tvalidation_0-logloss:0.53247\n",
      "[191]\tvalidation_0-logloss:0.53249\n",
      "[192]\tvalidation_0-logloss:0.53231\n",
      "[193]\tvalidation_0-logloss:0.53232\n",
      "[194]\tvalidation_0-logloss:0.53216\n",
      "[195]\tvalidation_0-logloss:0.53193\n",
      "[196]\tvalidation_0-logloss:0.53195\n",
      "[197]\tvalidation_0-logloss:0.53196\n",
      "[198]\tvalidation_0-logloss:0.53198\n",
      "[199]\tvalidation_0-logloss:0.53192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:58:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:58:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:58:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64074\n",
      "[1]\tvalidation_0-logloss:0.62572\n",
      "[2]\tvalidation_0-logloss:0.61468\n",
      "[3]\tvalidation_0-logloss:0.60650\n",
      "[4]\tvalidation_0-logloss:0.59940\n",
      "[5]\tvalidation_0-logloss:0.59473\n",
      "[6]\tvalidation_0-logloss:0.59008\n",
      "[7]\tvalidation_0-logloss:0.58748\n",
      "[8]\tvalidation_0-logloss:0.58449\n",
      "[9]\tvalidation_0-logloss:0.58066\n",
      "[10]\tvalidation_0-logloss:0.57881\n",
      "[11]\tvalidation_0-logloss:0.57677\n",
      "[12]\tvalidation_0-logloss:0.57454\n",
      "[13]\tvalidation_0-logloss:0.57322\n",
      "[14]\tvalidation_0-logloss:0.57148\n",
      "[15]\tvalidation_0-logloss:0.56957\n",
      "[16]\tvalidation_0-logloss:0.56913\n",
      "[17]\tvalidation_0-logloss:0.56801\n",
      "[18]\tvalidation_0-logloss:0.56599\n",
      "[19]\tvalidation_0-logloss:0.56478\n",
      "[20]\tvalidation_0-logloss:0.56330\n",
      "[21]\tvalidation_0-logloss:0.56220\n",
      "[22]\tvalidation_0-logloss:0.56134\n",
      "[23]\tvalidation_0-logloss:0.55927\n",
      "[24]\tvalidation_0-logloss:0.55872\n",
      "[25]\tvalidation_0-logloss:0.55828\n",
      "[26]\tvalidation_0-logloss:0.55782\n",
      "[27]\tvalidation_0-logloss:0.55718\n",
      "[28]\tvalidation_0-logloss:0.55631\n",
      "[29]\tvalidation_0-logloss:0.55576\n",
      "[30]\tvalidation_0-logloss:0.55534\n",
      "[31]\tvalidation_0-logloss:0.55492\n",
      "[32]\tvalidation_0-logloss:0.55473\n",
      "[33]\tvalidation_0-logloss:0.55402\n",
      "[34]\tvalidation_0-logloss:0.55376\n",
      "[35]\tvalidation_0-logloss:0.55304\n",
      "[36]\tvalidation_0-logloss:0.55294\n",
      "[37]\tvalidation_0-logloss:0.55284\n",
      "[38]\tvalidation_0-logloss:0.55204\n",
      "[39]\tvalidation_0-logloss:0.55111\n",
      "[40]\tvalidation_0-logloss:0.55063\n",
      "[41]\tvalidation_0-logloss:0.55036\n",
      "[42]\tvalidation_0-logloss:0.54966\n",
      "[43]\tvalidation_0-logloss:0.54951\n",
      "[44]\tvalidation_0-logloss:0.54945\n",
      "[45]\tvalidation_0-logloss:0.54874\n",
      "[46]\tvalidation_0-logloss:0.54832\n",
      "[47]\tvalidation_0-logloss:0.54752\n",
      "[48]\tvalidation_0-logloss:0.54745\n",
      "[49]\tvalidation_0-logloss:0.54731\n",
      "[50]\tvalidation_0-logloss:0.54722\n",
      "[51]\tvalidation_0-logloss:0.54717\n",
      "[52]\tvalidation_0-logloss:0.54697\n",
      "[53]\tvalidation_0-logloss:0.54691\n",
      "[54]\tvalidation_0-logloss:0.54663\n",
      "[55]\tvalidation_0-logloss:0.54582\n",
      "[56]\tvalidation_0-logloss:0.54531\n",
      "[57]\tvalidation_0-logloss:0.54478\n",
      "[58]\tvalidation_0-logloss:0.54456\n",
      "[59]\tvalidation_0-logloss:0.54447\n",
      "[60]\tvalidation_0-logloss:0.54443\n",
      "[61]\tvalidation_0-logloss:0.54439\n",
      "[62]\tvalidation_0-logloss:0.54407\n",
      "[63]\tvalidation_0-logloss:0.54368\n",
      "[64]\tvalidation_0-logloss:0.54364\n",
      "[65]\tvalidation_0-logloss:0.54336\n",
      "[66]\tvalidation_0-logloss:0.54324\n",
      "[67]\tvalidation_0-logloss:0.54310\n",
      "[68]\tvalidation_0-logloss:0.54307\n",
      "[69]\tvalidation_0-logloss:0.54292\n",
      "[70]\tvalidation_0-logloss:0.54289\n",
      "[71]\tvalidation_0-logloss:0.54286\n",
      "[72]\tvalidation_0-logloss:0.54277\n",
      "[73]\tvalidation_0-logloss:0.54252\n",
      "[74]\tvalidation_0-logloss:0.54245\n",
      "[75]\tvalidation_0-logloss:0.54242\n",
      "[76]\tvalidation_0-logloss:0.54230\n",
      "[77]\tvalidation_0-logloss:0.54210\n",
      "[78]\tvalidation_0-logloss:0.54196\n",
      "[79]\tvalidation_0-logloss:0.54180\n",
      "[80]\tvalidation_0-logloss:0.54146\n",
      "[81]\tvalidation_0-logloss:0.54116\n",
      "[82]\tvalidation_0-logloss:0.54114\n",
      "[83]\tvalidation_0-logloss:0.54112\n",
      "[84]\tvalidation_0-logloss:0.54104\n",
      "[85]\tvalidation_0-logloss:0.54082\n",
      "[86]\tvalidation_0-logloss:0.54075\n",
      "[87]\tvalidation_0-logloss:0.54054\n",
      "[88]\tvalidation_0-logloss:0.54053\n",
      "[89]\tvalidation_0-logloss:0.54040\n",
      "[90]\tvalidation_0-logloss:0.54037\n",
      "[91]\tvalidation_0-logloss:0.54033\n",
      "[92]\tvalidation_0-logloss:0.53992\n",
      "[93]\tvalidation_0-logloss:0.53961\n",
      "[94]\tvalidation_0-logloss:0.53943\n",
      "[95]\tvalidation_0-logloss:0.53942\n",
      "[96]\tvalidation_0-logloss:0.53940\n",
      "[97]\tvalidation_0-logloss:0.53923\n",
      "[98]\tvalidation_0-logloss:0.53920\n",
      "[99]\tvalidation_0-logloss:0.53918\n",
      "[100]\tvalidation_0-logloss:0.53883\n",
      "[101]\tvalidation_0-logloss:0.53875\n",
      "[102]\tvalidation_0-logloss:0.53858\n",
      "[103]\tvalidation_0-logloss:0.53856\n",
      "[104]\tvalidation_0-logloss:0.53853\n",
      "[105]\tvalidation_0-logloss:0.53849\n",
      "[106]\tvalidation_0-logloss:0.53843\n",
      "[107]\tvalidation_0-logloss:0.53823\n",
      "[108]\tvalidation_0-logloss:0.53821\n",
      "[109]\tvalidation_0-logloss:0.53801\n",
      "[110]\tvalidation_0-logloss:0.53799\n",
      "[111]\tvalidation_0-logloss:0.53791\n",
      "[112]\tvalidation_0-logloss:0.53790\n",
      "[113]\tvalidation_0-logloss:0.53784\n",
      "[114]\tvalidation_0-logloss:0.53776\n",
      "[115]\tvalidation_0-logloss:0.53753\n",
      "[116]\tvalidation_0-logloss:0.53753\n",
      "[117]\tvalidation_0-logloss:0.53752\n",
      "[118]\tvalidation_0-logloss:0.53735\n",
      "[119]\tvalidation_0-logloss:0.53734\n",
      "[120]\tvalidation_0-logloss:0.53732\n",
      "[121]\tvalidation_0-logloss:0.53713\n",
      "[122]\tvalidation_0-logloss:0.53708\n",
      "[123]\tvalidation_0-logloss:0.53708\n",
      "[124]\tvalidation_0-logloss:0.53667\n",
      "[125]\tvalidation_0-logloss:0.53666\n",
      "[126]\tvalidation_0-logloss:0.53655\n",
      "[127]\tvalidation_0-logloss:0.53617\n",
      "[128]\tvalidation_0-logloss:0.53618\n",
      "[129]\tvalidation_0-logloss:0.53595\n",
      "[130]\tvalidation_0-logloss:0.53589\n",
      "[131]\tvalidation_0-logloss:0.53588\n",
      "[132]\tvalidation_0-logloss:0.53588\n",
      "[133]\tvalidation_0-logloss:0.53583\n",
      "[134]\tvalidation_0-logloss:0.53575\n",
      "[135]\tvalidation_0-logloss:0.53566\n",
      "[136]\tvalidation_0-logloss:0.53565\n",
      "[137]\tvalidation_0-logloss:0.53559\n",
      "[138]\tvalidation_0-logloss:0.53541\n",
      "[139]\tvalidation_0-logloss:0.53529\n",
      "[140]\tvalidation_0-logloss:0.53506\n",
      "[141]\tvalidation_0-logloss:0.53505\n",
      "[142]\tvalidation_0-logloss:0.53469\n",
      "[143]\tvalidation_0-logloss:0.53468\n",
      "[144]\tvalidation_0-logloss:0.53456\n",
      "[145]\tvalidation_0-logloss:0.53442\n",
      "[146]\tvalidation_0-logloss:0.53443\n",
      "[147]\tvalidation_0-logloss:0.53442\n",
      "[148]\tvalidation_0-logloss:0.53440\n",
      "[149]\tvalidation_0-logloss:0.53431\n",
      "[150]\tvalidation_0-logloss:0.53408\n",
      "[151]\tvalidation_0-logloss:0.53404\n",
      "[152]\tvalidation_0-logloss:0.53404\n",
      "[153]\tvalidation_0-logloss:0.53388\n",
      "[154]\tvalidation_0-logloss:0.53389\n",
      "[155]\tvalidation_0-logloss:0.53389\n",
      "[156]\tvalidation_0-logloss:0.53389\n",
      "[157]\tvalidation_0-logloss:0.53382\n",
      "[158]\tvalidation_0-logloss:0.53382\n",
      "[159]\tvalidation_0-logloss:0.53349\n",
      "[160]\tvalidation_0-logloss:0.53349\n",
      "[161]\tvalidation_0-logloss:0.53350\n",
      "[162]\tvalidation_0-logloss:0.53351\n",
      "[163]\tvalidation_0-logloss:0.53341\n",
      "[164]\tvalidation_0-logloss:0.53321\n",
      "[165]\tvalidation_0-logloss:0.53320\n",
      "[166]\tvalidation_0-logloss:0.53320\n",
      "[167]\tvalidation_0-logloss:0.53321\n",
      "[168]\tvalidation_0-logloss:0.53314\n",
      "[169]\tvalidation_0-logloss:0.53306\n",
      "[170]\tvalidation_0-logloss:0.53299\n",
      "[171]\tvalidation_0-logloss:0.53283\n",
      "[172]\tvalidation_0-logloss:0.53280\n",
      "[173]\tvalidation_0-logloss:0.53281\n",
      "[174]\tvalidation_0-logloss:0.53276\n",
      "[175]\tvalidation_0-logloss:0.53275\n",
      "[176]\tvalidation_0-logloss:0.53266\n",
      "[177]\tvalidation_0-logloss:0.53258\n",
      "[178]\tvalidation_0-logloss:0.53255\n",
      "[179]\tvalidation_0-logloss:0.53234\n",
      "[180]\tvalidation_0-logloss:0.53231\n",
      "[181]\tvalidation_0-logloss:0.53231\n",
      "[182]\tvalidation_0-logloss:0.53227\n",
      "[183]\tvalidation_0-logloss:0.53227\n",
      "[184]\tvalidation_0-logloss:0.53225\n",
      "[185]\tvalidation_0-logloss:0.53201\n",
      "[186]\tvalidation_0-logloss:0.53182\n",
      "[187]\tvalidation_0-logloss:0.53172\n",
      "[188]\tvalidation_0-logloss:0.53161\n",
      "[189]\tvalidation_0-logloss:0.53152\n",
      "[190]\tvalidation_0-logloss:0.53152\n",
      "[191]\tvalidation_0-logloss:0.53149\n",
      "[192]\tvalidation_0-logloss:0.53142\n",
      "[193]\tvalidation_0-logloss:0.53132\n",
      "[194]\tvalidation_0-logloss:0.53130\n",
      "[195]\tvalidation_0-logloss:0.53122\n",
      "[196]\tvalidation_0-logloss:0.53118\n",
      "[197]\tvalidation_0-logloss:0.53097\n",
      "[198]\tvalidation_0-logloss:0.53078\n",
      "[199]\tvalidation_0-logloss:0.53060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:59:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:59:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64058\n",
      "[1]\tvalidation_0-logloss:0.62558\n",
      "[2]\tvalidation_0-logloss:0.61457\n",
      "[3]\tvalidation_0-logloss:0.60569\n",
      "[4]\tvalidation_0-logloss:0.59888\n",
      "[5]\tvalidation_0-logloss:0.59399\n",
      "[6]\tvalidation_0-logloss:0.58955\n",
      "[7]\tvalidation_0-logloss:0.58676\n",
      "[8]\tvalidation_0-logloss:0.58434\n",
      "[9]\tvalidation_0-logloss:0.58101\n",
      "[10]\tvalidation_0-logloss:0.57928\n",
      "[11]\tvalidation_0-logloss:0.57552\n",
      "[12]\tvalidation_0-logloss:0.57346\n",
      "[13]\tvalidation_0-logloss:0.57147\n",
      "[14]\tvalidation_0-logloss:0.56934\n",
      "[15]\tvalidation_0-logloss:0.56813\n",
      "[16]\tvalidation_0-logloss:0.56687\n",
      "[17]\tvalidation_0-logloss:0.56525\n",
      "[18]\tvalidation_0-logloss:0.56441\n",
      "[19]\tvalidation_0-logloss:0.56365\n",
      "[20]\tvalidation_0-logloss:0.56273\n",
      "[21]\tvalidation_0-logloss:0.56175\n",
      "[22]\tvalidation_0-logloss:0.56104\n",
      "[23]\tvalidation_0-logloss:0.56031\n",
      "[24]\tvalidation_0-logloss:0.55916\n",
      "[25]\tvalidation_0-logloss:0.55795\n",
      "[26]\tvalidation_0-logloss:0.55726\n",
      "[27]\tvalidation_0-logloss:0.55665\n",
      "[28]\tvalidation_0-logloss:0.55640\n",
      "[29]\tvalidation_0-logloss:0.55550\n",
      "[30]\tvalidation_0-logloss:0.55525\n",
      "[31]\tvalidation_0-logloss:0.55484\n",
      "[32]\tvalidation_0-logloss:0.55446\n",
      "[33]\tvalidation_0-logloss:0.55399\n",
      "[34]\tvalidation_0-logloss:0.55360\n",
      "[35]\tvalidation_0-logloss:0.55350\n",
      "[36]\tvalidation_0-logloss:0.55312\n",
      "[37]\tvalidation_0-logloss:0.55296\n",
      "[38]\tvalidation_0-logloss:0.55166\n",
      "[39]\tvalidation_0-logloss:0.55083\n",
      "[40]\tvalidation_0-logloss:0.55064\n",
      "[41]\tvalidation_0-logloss:0.55031\n",
      "[42]\tvalidation_0-logloss:0.54980\n",
      "[43]\tvalidation_0-logloss:0.54899\n",
      "[44]\tvalidation_0-logloss:0.54892\n",
      "[45]\tvalidation_0-logloss:0.54877\n",
      "[46]\tvalidation_0-logloss:0.54853\n",
      "[47]\tvalidation_0-logloss:0.54843\n",
      "[48]\tvalidation_0-logloss:0.54832\n",
      "[49]\tvalidation_0-logloss:0.54821\n",
      "[50]\tvalidation_0-logloss:0.54814\n",
      "[51]\tvalidation_0-logloss:0.54783\n",
      "[52]\tvalidation_0-logloss:0.54747\n",
      "[53]\tvalidation_0-logloss:0.54738\n",
      "[54]\tvalidation_0-logloss:0.54734\n",
      "[55]\tvalidation_0-logloss:0.54724\n",
      "[56]\tvalidation_0-logloss:0.54719\n",
      "[57]\tvalidation_0-logloss:0.54712\n",
      "[58]\tvalidation_0-logloss:0.54626\n",
      "[59]\tvalidation_0-logloss:0.54613\n",
      "[60]\tvalidation_0-logloss:0.54522\n",
      "[61]\tvalidation_0-logloss:0.54486\n",
      "[62]\tvalidation_0-logloss:0.54440\n",
      "[63]\tvalidation_0-logloss:0.54420\n",
      "[64]\tvalidation_0-logloss:0.54404\n",
      "[65]\tvalidation_0-logloss:0.54400\n",
      "[66]\tvalidation_0-logloss:0.54398\n",
      "[67]\tvalidation_0-logloss:0.54382\n",
      "[68]\tvalidation_0-logloss:0.54351\n",
      "[69]\tvalidation_0-logloss:0.54338\n",
      "[70]\tvalidation_0-logloss:0.54331\n",
      "[71]\tvalidation_0-logloss:0.54329\n",
      "[72]\tvalidation_0-logloss:0.54325\n",
      "[73]\tvalidation_0-logloss:0.54313\n",
      "[74]\tvalidation_0-logloss:0.54285\n",
      "[75]\tvalidation_0-logloss:0.54283\n",
      "[76]\tvalidation_0-logloss:0.54279\n",
      "[77]\tvalidation_0-logloss:0.54275\n",
      "[78]\tvalidation_0-logloss:0.54273\n",
      "[79]\tvalidation_0-logloss:0.54256\n",
      "[80]\tvalidation_0-logloss:0.54243\n",
      "[81]\tvalidation_0-logloss:0.54241\n",
      "[82]\tvalidation_0-logloss:0.54238\n",
      "[83]\tvalidation_0-logloss:0.54217\n",
      "[84]\tvalidation_0-logloss:0.54172\n",
      "[85]\tvalidation_0-logloss:0.54134\n",
      "[86]\tvalidation_0-logloss:0.54116\n",
      "[87]\tvalidation_0-logloss:0.54084\n",
      "[88]\tvalidation_0-logloss:0.54078\n",
      "[89]\tvalidation_0-logloss:0.54064\n",
      "[90]\tvalidation_0-logloss:0.54062\n",
      "[91]\tvalidation_0-logloss:0.54035\n",
      "[92]\tvalidation_0-logloss:0.54033\n",
      "[93]\tvalidation_0-logloss:0.54032\n",
      "[94]\tvalidation_0-logloss:0.54020\n",
      "[95]\tvalidation_0-logloss:0.54020\n",
      "[96]\tvalidation_0-logloss:0.54001\n",
      "[97]\tvalidation_0-logloss:0.53969\n",
      "[98]\tvalidation_0-logloss:0.53960\n",
      "[99]\tvalidation_0-logloss:0.53939\n",
      "[100]\tvalidation_0-logloss:0.53911\n",
      "[101]\tvalidation_0-logloss:0.53908\n",
      "[102]\tvalidation_0-logloss:0.53881\n",
      "[103]\tvalidation_0-logloss:0.53867\n",
      "[104]\tvalidation_0-logloss:0.53864\n",
      "[105]\tvalidation_0-logloss:0.53864\n",
      "[106]\tvalidation_0-logloss:0.53851\n",
      "[107]\tvalidation_0-logloss:0.53849\n",
      "[108]\tvalidation_0-logloss:0.53848\n",
      "[109]\tvalidation_0-logloss:0.53832\n",
      "[110]\tvalidation_0-logloss:0.53833\n",
      "[111]\tvalidation_0-logloss:0.53833\n",
      "[112]\tvalidation_0-logloss:0.53831\n",
      "[113]\tvalidation_0-logloss:0.53825\n",
      "[114]\tvalidation_0-logloss:0.53794\n",
      "[115]\tvalidation_0-logloss:0.53761\n",
      "[116]\tvalidation_0-logloss:0.53753\n",
      "[117]\tvalidation_0-logloss:0.53752\n",
      "[118]\tvalidation_0-logloss:0.53751\n",
      "[119]\tvalidation_0-logloss:0.53719\n",
      "[120]\tvalidation_0-logloss:0.53708\n",
      "[121]\tvalidation_0-logloss:0.53680\n",
      "[122]\tvalidation_0-logloss:0.53658\n",
      "[123]\tvalidation_0-logloss:0.53654\n",
      "[124]\tvalidation_0-logloss:0.53641\n",
      "[125]\tvalidation_0-logloss:0.53641\n",
      "[126]\tvalidation_0-logloss:0.53610\n",
      "[127]\tvalidation_0-logloss:0.53609\n",
      "[128]\tvalidation_0-logloss:0.53608\n",
      "[129]\tvalidation_0-logloss:0.53598\n",
      "[130]\tvalidation_0-logloss:0.53594\n",
      "[131]\tvalidation_0-logloss:0.53588\n",
      "[132]\tvalidation_0-logloss:0.53589\n",
      "[133]\tvalidation_0-logloss:0.53576\n",
      "[134]\tvalidation_0-logloss:0.53571\n",
      "[135]\tvalidation_0-logloss:0.53571\n",
      "[136]\tvalidation_0-logloss:0.53571\n",
      "[137]\tvalidation_0-logloss:0.53539\n",
      "[138]\tvalidation_0-logloss:0.53509\n",
      "[139]\tvalidation_0-logloss:0.53511\n",
      "[140]\tvalidation_0-logloss:0.53509\n",
      "[141]\tvalidation_0-logloss:0.53509\n",
      "[142]\tvalidation_0-logloss:0.53504\n",
      "[143]\tvalidation_0-logloss:0.53490\n",
      "[144]\tvalidation_0-logloss:0.53487\n",
      "[145]\tvalidation_0-logloss:0.53482\n",
      "[146]\tvalidation_0-logloss:0.53476\n",
      "[147]\tvalidation_0-logloss:0.53474\n",
      "[148]\tvalidation_0-logloss:0.53474\n",
      "[149]\tvalidation_0-logloss:0.53471\n",
      "[150]\tvalidation_0-logloss:0.53426\n",
      "[151]\tvalidation_0-logloss:0.53426\n",
      "[152]\tvalidation_0-logloss:0.53425\n",
      "[153]\tvalidation_0-logloss:0.53423\n",
      "[154]\tvalidation_0-logloss:0.53423\n",
      "[155]\tvalidation_0-logloss:0.53423\n",
      "[156]\tvalidation_0-logloss:0.53411\n",
      "[157]\tvalidation_0-logloss:0.53393\n",
      "[158]\tvalidation_0-logloss:0.53391\n",
      "[159]\tvalidation_0-logloss:0.53378\n",
      "[160]\tvalidation_0-logloss:0.53360\n",
      "[161]\tvalidation_0-logloss:0.53347\n",
      "[162]\tvalidation_0-logloss:0.53347\n",
      "[163]\tvalidation_0-logloss:0.53310\n",
      "[164]\tvalidation_0-logloss:0.53278\n",
      "[165]\tvalidation_0-logloss:0.53277\n",
      "[166]\tvalidation_0-logloss:0.53277\n",
      "[167]\tvalidation_0-logloss:0.53259\n",
      "[168]\tvalidation_0-logloss:0.53260\n",
      "[169]\tvalidation_0-logloss:0.53260\n",
      "[170]\tvalidation_0-logloss:0.53245\n",
      "[171]\tvalidation_0-logloss:0.53205\n",
      "[172]\tvalidation_0-logloss:0.53205\n",
      "[173]\tvalidation_0-logloss:0.53187\n",
      "[174]\tvalidation_0-logloss:0.53184\n",
      "[175]\tvalidation_0-logloss:0.53184\n",
      "[176]\tvalidation_0-logloss:0.53183\n",
      "[177]\tvalidation_0-logloss:0.53169\n",
      "[178]\tvalidation_0-logloss:0.53169\n",
      "[179]\tvalidation_0-logloss:0.53157\n",
      "[180]\tvalidation_0-logloss:0.53154\n",
      "[181]\tvalidation_0-logloss:0.53154\n",
      "[182]\tvalidation_0-logloss:0.53154\n",
      "[183]\tvalidation_0-logloss:0.53150\n",
      "[184]\tvalidation_0-logloss:0.53147\n",
      "[185]\tvalidation_0-logloss:0.53137\n",
      "[186]\tvalidation_0-logloss:0.53138\n",
      "[187]\tvalidation_0-logloss:0.53125\n",
      "[188]\tvalidation_0-logloss:0.53125\n",
      "[189]\tvalidation_0-logloss:0.53123\n",
      "[190]\tvalidation_0-logloss:0.53123\n",
      "[191]\tvalidation_0-logloss:0.53123\n",
      "[192]\tvalidation_0-logloss:0.53123\n",
      "[193]\tvalidation_0-logloss:0.53121\n",
      "[194]\tvalidation_0-logloss:0.53118\n",
      "[195]\tvalidation_0-logloss:0.53117\n",
      "[196]\tvalidation_0-logloss:0.53115\n",
      "[197]\tvalidation_0-logloss:0.53115\n",
      "[198]\tvalidation_0-logloss:0.53117\n",
      "[199]\tvalidation_0-logloss:0.53118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:59:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:00:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64037\n",
      "[1]\tvalidation_0-logloss:0.62519\n",
      "[2]\tvalidation_0-logloss:0.61472\n",
      "[3]\tvalidation_0-logloss:0.60601\n",
      "[4]\tvalidation_0-logloss:0.59916\n",
      "[5]\tvalidation_0-logloss:0.59425\n",
      "[6]\tvalidation_0-logloss:0.59042\n",
      "[7]\tvalidation_0-logloss:0.58673\n",
      "[8]\tvalidation_0-logloss:0.58352\n",
      "[9]\tvalidation_0-logloss:0.58136\n",
      "[10]\tvalidation_0-logloss:0.57959\n",
      "[11]\tvalidation_0-logloss:0.57672\n",
      "[12]\tvalidation_0-logloss:0.57484\n",
      "[13]\tvalidation_0-logloss:0.57303\n",
      "[14]\tvalidation_0-logloss:0.57016\n",
      "[15]\tvalidation_0-logloss:0.56919\n",
      "[16]\tvalidation_0-logloss:0.56780\n",
      "[17]\tvalidation_0-logloss:0.56690\n",
      "[18]\tvalidation_0-logloss:0.56554\n",
      "[19]\tvalidation_0-logloss:0.56465\n",
      "[20]\tvalidation_0-logloss:0.56384\n",
      "[21]\tvalidation_0-logloss:0.56257\n",
      "[22]\tvalidation_0-logloss:0.56086\n",
      "[23]\tvalidation_0-logloss:0.56005\n",
      "[24]\tvalidation_0-logloss:0.55914\n",
      "[25]\tvalidation_0-logloss:0.55869\n",
      "[26]\tvalidation_0-logloss:0.55745\n",
      "[27]\tvalidation_0-logloss:0.55715\n",
      "[28]\tvalidation_0-logloss:0.55669\n",
      "[29]\tvalidation_0-logloss:0.55573\n",
      "[30]\tvalidation_0-logloss:0.55460\n",
      "[31]\tvalidation_0-logloss:0.55425\n",
      "[32]\tvalidation_0-logloss:0.55379\n",
      "[33]\tvalidation_0-logloss:0.55344\n",
      "[34]\tvalidation_0-logloss:0.55285\n",
      "[35]\tvalidation_0-logloss:0.55273\n",
      "[36]\tvalidation_0-logloss:0.55251\n",
      "[37]\tvalidation_0-logloss:0.55210\n",
      "[38]\tvalidation_0-logloss:0.55169\n",
      "[39]\tvalidation_0-logloss:0.55154\n",
      "[40]\tvalidation_0-logloss:0.55121\n",
      "[41]\tvalidation_0-logloss:0.55105\n",
      "[42]\tvalidation_0-logloss:0.55096\n",
      "[43]\tvalidation_0-logloss:0.54968\n",
      "[44]\tvalidation_0-logloss:0.54905\n",
      "[45]\tvalidation_0-logloss:0.54899\n",
      "[46]\tvalidation_0-logloss:0.54830\n",
      "[47]\tvalidation_0-logloss:0.54813\n",
      "[48]\tvalidation_0-logloss:0.54766\n",
      "[49]\tvalidation_0-logloss:0.54755\n",
      "[50]\tvalidation_0-logloss:0.54748\n",
      "[51]\tvalidation_0-logloss:0.54716\n",
      "[52]\tvalidation_0-logloss:0.54671\n",
      "[53]\tvalidation_0-logloss:0.54657\n",
      "[54]\tvalidation_0-logloss:0.54652\n",
      "[55]\tvalidation_0-logloss:0.54643\n",
      "[56]\tvalidation_0-logloss:0.54639\n",
      "[57]\tvalidation_0-logloss:0.54626\n",
      "[58]\tvalidation_0-logloss:0.54584\n",
      "[59]\tvalidation_0-logloss:0.54579\n",
      "[60]\tvalidation_0-logloss:0.54573\n",
      "[61]\tvalidation_0-logloss:0.54512\n",
      "[62]\tvalidation_0-logloss:0.54493\n",
      "[63]\tvalidation_0-logloss:0.54479\n",
      "[64]\tvalidation_0-logloss:0.54466\n",
      "[65]\tvalidation_0-logloss:0.54462\n",
      "[66]\tvalidation_0-logloss:0.54432\n",
      "[67]\tvalidation_0-logloss:0.54429\n",
      "[68]\tvalidation_0-logloss:0.54400\n",
      "[69]\tvalidation_0-logloss:0.54366\n",
      "[70]\tvalidation_0-logloss:0.54338\n",
      "[71]\tvalidation_0-logloss:0.54316\n",
      "[72]\tvalidation_0-logloss:0.54276\n",
      "[73]\tvalidation_0-logloss:0.54272\n",
      "[74]\tvalidation_0-logloss:0.54268\n",
      "[75]\tvalidation_0-logloss:0.54246\n",
      "[76]\tvalidation_0-logloss:0.54243\n",
      "[77]\tvalidation_0-logloss:0.54234\n",
      "[78]\tvalidation_0-logloss:0.54229\n",
      "[79]\tvalidation_0-logloss:0.54227\n",
      "[80]\tvalidation_0-logloss:0.54224\n",
      "[81]\tvalidation_0-logloss:0.54184\n",
      "[82]\tvalidation_0-logloss:0.54182\n",
      "[83]\tvalidation_0-logloss:0.54174\n",
      "[84]\tvalidation_0-logloss:0.54164\n",
      "[85]\tvalidation_0-logloss:0.54162\n",
      "[86]\tvalidation_0-logloss:0.54159\n",
      "[87]\tvalidation_0-logloss:0.54158\n",
      "[88]\tvalidation_0-logloss:0.54157\n",
      "[89]\tvalidation_0-logloss:0.54156\n",
      "[90]\tvalidation_0-logloss:0.54152\n",
      "[91]\tvalidation_0-logloss:0.54150\n",
      "[92]\tvalidation_0-logloss:0.54136\n",
      "[93]\tvalidation_0-logloss:0.54109\n",
      "[94]\tvalidation_0-logloss:0.54107\n",
      "[95]\tvalidation_0-logloss:0.54082\n",
      "[96]\tvalidation_0-logloss:0.54081\n",
      "[97]\tvalidation_0-logloss:0.54067\n",
      "[98]\tvalidation_0-logloss:0.54035\n",
      "[99]\tvalidation_0-logloss:0.54020\n",
      "[100]\tvalidation_0-logloss:0.53985\n",
      "[101]\tvalidation_0-logloss:0.53985\n",
      "[102]\tvalidation_0-logloss:0.53976\n",
      "[103]\tvalidation_0-logloss:0.53965\n",
      "[104]\tvalidation_0-logloss:0.53958\n",
      "[105]\tvalidation_0-logloss:0.53943\n",
      "[106]\tvalidation_0-logloss:0.53942\n",
      "[107]\tvalidation_0-logloss:0.53943\n",
      "[108]\tvalidation_0-logloss:0.53942\n",
      "[109]\tvalidation_0-logloss:0.53920\n",
      "[110]\tvalidation_0-logloss:0.53911\n",
      "[111]\tvalidation_0-logloss:0.53882\n",
      "[112]\tvalidation_0-logloss:0.53874\n",
      "[113]\tvalidation_0-logloss:0.53860\n",
      "[114]\tvalidation_0-logloss:0.53858\n",
      "[115]\tvalidation_0-logloss:0.53846\n",
      "[116]\tvalidation_0-logloss:0.53839\n",
      "[117]\tvalidation_0-logloss:0.53823\n",
      "[118]\tvalidation_0-logloss:0.53821\n",
      "[119]\tvalidation_0-logloss:0.53801\n",
      "[120]\tvalidation_0-logloss:0.53779\n",
      "[121]\tvalidation_0-logloss:0.53764\n",
      "[122]\tvalidation_0-logloss:0.53735\n",
      "[123]\tvalidation_0-logloss:0.53730\n",
      "[124]\tvalidation_0-logloss:0.53711\n",
      "[125]\tvalidation_0-logloss:0.53705\n",
      "[126]\tvalidation_0-logloss:0.53700\n",
      "[127]\tvalidation_0-logloss:0.53701\n",
      "[128]\tvalidation_0-logloss:0.53698\n",
      "[129]\tvalidation_0-logloss:0.53692\n",
      "[130]\tvalidation_0-logloss:0.53655\n",
      "[131]\tvalidation_0-logloss:0.53655\n",
      "[132]\tvalidation_0-logloss:0.53652\n",
      "[133]\tvalidation_0-logloss:0.53653\n",
      "[134]\tvalidation_0-logloss:0.53649\n",
      "[135]\tvalidation_0-logloss:0.53636\n",
      "[136]\tvalidation_0-logloss:0.53637\n",
      "[137]\tvalidation_0-logloss:0.53631\n",
      "[138]\tvalidation_0-logloss:0.53630\n",
      "[139]\tvalidation_0-logloss:0.53629\n",
      "[140]\tvalidation_0-logloss:0.53612\n",
      "[141]\tvalidation_0-logloss:0.53612\n",
      "[142]\tvalidation_0-logloss:0.53612\n",
      "[143]\tvalidation_0-logloss:0.53583\n",
      "[144]\tvalidation_0-logloss:0.53581\n",
      "[145]\tvalidation_0-logloss:0.53562\n",
      "[146]\tvalidation_0-logloss:0.53557\n",
      "[147]\tvalidation_0-logloss:0.53518\n",
      "[148]\tvalidation_0-logloss:0.53518\n",
      "[149]\tvalidation_0-logloss:0.53503\n",
      "[150]\tvalidation_0-logloss:0.53492\n",
      "[151]\tvalidation_0-logloss:0.53471\n",
      "[152]\tvalidation_0-logloss:0.53444\n",
      "[153]\tvalidation_0-logloss:0.53420\n",
      "[154]\tvalidation_0-logloss:0.53418\n",
      "[155]\tvalidation_0-logloss:0.53418\n",
      "[156]\tvalidation_0-logloss:0.53418\n",
      "[157]\tvalidation_0-logloss:0.53417\n",
      "[158]\tvalidation_0-logloss:0.53413\n",
      "[159]\tvalidation_0-logloss:0.53412\n",
      "[160]\tvalidation_0-logloss:0.53406\n",
      "[161]\tvalidation_0-logloss:0.53405\n",
      "[162]\tvalidation_0-logloss:0.53387\n",
      "[163]\tvalidation_0-logloss:0.53383\n",
      "[164]\tvalidation_0-logloss:0.53370\n",
      "[165]\tvalidation_0-logloss:0.53346\n",
      "[166]\tvalidation_0-logloss:0.53348\n",
      "[167]\tvalidation_0-logloss:0.53313\n",
      "[168]\tvalidation_0-logloss:0.53314\n",
      "[169]\tvalidation_0-logloss:0.53313\n",
      "[170]\tvalidation_0-logloss:0.53312\n",
      "[171]\tvalidation_0-logloss:0.53313\n",
      "[172]\tvalidation_0-logloss:0.53311\n",
      "[173]\tvalidation_0-logloss:0.53291\n",
      "[174]\tvalidation_0-logloss:0.53291\n",
      "[175]\tvalidation_0-logloss:0.53290\n",
      "[176]\tvalidation_0-logloss:0.53285\n",
      "[177]\tvalidation_0-logloss:0.53250\n",
      "[178]\tvalidation_0-logloss:0.53251\n",
      "[179]\tvalidation_0-logloss:0.53246\n",
      "[180]\tvalidation_0-logloss:0.53245\n",
      "[181]\tvalidation_0-logloss:0.53236\n",
      "[182]\tvalidation_0-logloss:0.53235\n",
      "[183]\tvalidation_0-logloss:0.53235\n",
      "[184]\tvalidation_0-logloss:0.53234\n",
      "[185]\tvalidation_0-logloss:0.53233\n",
      "[186]\tvalidation_0-logloss:0.53224\n",
      "[187]\tvalidation_0-logloss:0.53213\n",
      "[188]\tvalidation_0-logloss:0.53212\n",
      "[189]\tvalidation_0-logloss:0.53187\n",
      "[190]\tvalidation_0-logloss:0.53186\n",
      "[191]\tvalidation_0-logloss:0.53183\n",
      "[192]\tvalidation_0-logloss:0.53178\n",
      "[193]\tvalidation_0-logloss:0.53179\n",
      "[194]\tvalidation_0-logloss:0.53180\n",
      "[195]\tvalidation_0-logloss:0.53167\n",
      "[196]\tvalidation_0-logloss:0.53159\n",
      "[197]\tvalidation_0-logloss:0.53159\n",
      "[198]\tvalidation_0-logloss:0.53160\n",
      "[199]\tvalidation_0-logloss:0.53159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:00:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:00:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64072\n",
      "[1]\tvalidation_0-logloss:0.62577\n",
      "[2]\tvalidation_0-logloss:0.61473\n",
      "[3]\tvalidation_0-logloss:0.60615\n",
      "[4]\tvalidation_0-logloss:0.59960\n",
      "[5]\tvalidation_0-logloss:0.59509\n",
      "[6]\tvalidation_0-logloss:0.59041\n",
      "[7]\tvalidation_0-logloss:0.58732\n",
      "[8]\tvalidation_0-logloss:0.58438\n",
      "[9]\tvalidation_0-logloss:0.58160\n",
      "[10]\tvalidation_0-logloss:0.57896\n",
      "[11]\tvalidation_0-logloss:0.57742\n",
      "[12]\tvalidation_0-logloss:0.57536\n",
      "[13]\tvalidation_0-logloss:0.57362\n",
      "[14]\tvalidation_0-logloss:0.57186\n",
      "[15]\tvalidation_0-logloss:0.57074\n",
      "[16]\tvalidation_0-logloss:0.56860\n",
      "[17]\tvalidation_0-logloss:0.56692\n",
      "[18]\tvalidation_0-logloss:0.56636\n",
      "[19]\tvalidation_0-logloss:0.56487\n",
      "[20]\tvalidation_0-logloss:0.56375\n",
      "[21]\tvalidation_0-logloss:0.56273\n",
      "[22]\tvalidation_0-logloss:0.56213\n",
      "[23]\tvalidation_0-logloss:0.56130\n",
      "[24]\tvalidation_0-logloss:0.56023\n",
      "[25]\tvalidation_0-logloss:0.56002\n",
      "[26]\tvalidation_0-logloss:0.55910\n",
      "[27]\tvalidation_0-logloss:0.55877\n",
      "[28]\tvalidation_0-logloss:0.55838\n",
      "[29]\tvalidation_0-logloss:0.55764\n",
      "[30]\tvalidation_0-logloss:0.55666\n",
      "[31]\tvalidation_0-logloss:0.55650\n",
      "[32]\tvalidation_0-logloss:0.55566\n",
      "[33]\tvalidation_0-logloss:0.55525\n",
      "[34]\tvalidation_0-logloss:0.55376\n",
      "[35]\tvalidation_0-logloss:0.55348\n",
      "[36]\tvalidation_0-logloss:0.55299\n",
      "[37]\tvalidation_0-logloss:0.55287\n",
      "[38]\tvalidation_0-logloss:0.55270\n",
      "[39]\tvalidation_0-logloss:0.55241\n",
      "[40]\tvalidation_0-logloss:0.55191\n",
      "[41]\tvalidation_0-logloss:0.55110\n",
      "[42]\tvalidation_0-logloss:0.55042\n",
      "[43]\tvalidation_0-logloss:0.55014\n",
      "[44]\tvalidation_0-logloss:0.54962\n",
      "[45]\tvalidation_0-logloss:0.54944\n",
      "[46]\tvalidation_0-logloss:0.54935\n",
      "[47]\tvalidation_0-logloss:0.54929\n",
      "[48]\tvalidation_0-logloss:0.54890\n",
      "[49]\tvalidation_0-logloss:0.54865\n",
      "[50]\tvalidation_0-logloss:0.54814\n",
      "[51]\tvalidation_0-logloss:0.54783\n",
      "[52]\tvalidation_0-logloss:0.54779\n",
      "[53]\tvalidation_0-logloss:0.54733\n",
      "[54]\tvalidation_0-logloss:0.54719\n",
      "[55]\tvalidation_0-logloss:0.54710\n",
      "[56]\tvalidation_0-logloss:0.54705\n",
      "[57]\tvalidation_0-logloss:0.54699\n",
      "[58]\tvalidation_0-logloss:0.54691\n",
      "[59]\tvalidation_0-logloss:0.54646\n",
      "[60]\tvalidation_0-logloss:0.54634\n",
      "[61]\tvalidation_0-logloss:0.54624\n",
      "[62]\tvalidation_0-logloss:0.54580\n",
      "[63]\tvalidation_0-logloss:0.54507\n",
      "[64]\tvalidation_0-logloss:0.54479\n",
      "[65]\tvalidation_0-logloss:0.54473\n",
      "[66]\tvalidation_0-logloss:0.54471\n",
      "[67]\tvalidation_0-logloss:0.54468\n",
      "[68]\tvalidation_0-logloss:0.54441\n",
      "[69]\tvalidation_0-logloss:0.54425\n",
      "[70]\tvalidation_0-logloss:0.54420\n",
      "[71]\tvalidation_0-logloss:0.54409\n",
      "[72]\tvalidation_0-logloss:0.54405\n",
      "[73]\tvalidation_0-logloss:0.54355\n",
      "[74]\tvalidation_0-logloss:0.54351\n",
      "[75]\tvalidation_0-logloss:0.54316\n",
      "[76]\tvalidation_0-logloss:0.54295\n",
      "[77]\tvalidation_0-logloss:0.54292\n",
      "[78]\tvalidation_0-logloss:0.54290\n",
      "[79]\tvalidation_0-logloss:0.54284\n",
      "[80]\tvalidation_0-logloss:0.54281\n",
      "[81]\tvalidation_0-logloss:0.54264\n",
      "[82]\tvalidation_0-logloss:0.54262\n",
      "[83]\tvalidation_0-logloss:0.54242\n",
      "[84]\tvalidation_0-logloss:0.54234\n",
      "[85]\tvalidation_0-logloss:0.54218\n",
      "[86]\tvalidation_0-logloss:0.54215\n",
      "[87]\tvalidation_0-logloss:0.54214\n",
      "[88]\tvalidation_0-logloss:0.54164\n",
      "[89]\tvalidation_0-logloss:0.54154\n",
      "[90]\tvalidation_0-logloss:0.54115\n",
      "[91]\tvalidation_0-logloss:0.54070\n",
      "[92]\tvalidation_0-logloss:0.54058\n",
      "[93]\tvalidation_0-logloss:0.54057\n",
      "[94]\tvalidation_0-logloss:0.54051\n",
      "[95]\tvalidation_0-logloss:0.54047\n",
      "[96]\tvalidation_0-logloss:0.54033\n",
      "[97]\tvalidation_0-logloss:0.54003\n",
      "[98]\tvalidation_0-logloss:0.54000\n",
      "[99]\tvalidation_0-logloss:0.53994\n",
      "[100]\tvalidation_0-logloss:0.53993\n",
      "[101]\tvalidation_0-logloss:0.53974\n",
      "[102]\tvalidation_0-logloss:0.53971\n",
      "[103]\tvalidation_0-logloss:0.53968\n",
      "[104]\tvalidation_0-logloss:0.53968\n",
      "[105]\tvalidation_0-logloss:0.53960\n",
      "[106]\tvalidation_0-logloss:0.53959\n",
      "[107]\tvalidation_0-logloss:0.53947\n",
      "[108]\tvalidation_0-logloss:0.53935\n",
      "[109]\tvalidation_0-logloss:0.53914\n",
      "[110]\tvalidation_0-logloss:0.53895\n",
      "[111]\tvalidation_0-logloss:0.53895\n",
      "[112]\tvalidation_0-logloss:0.53870\n",
      "[113]\tvalidation_0-logloss:0.53869\n",
      "[114]\tvalidation_0-logloss:0.53857\n",
      "[115]\tvalidation_0-logloss:0.53851\n",
      "[116]\tvalidation_0-logloss:0.53849\n",
      "[117]\tvalidation_0-logloss:0.53839\n",
      "[118]\tvalidation_0-logloss:0.53826\n",
      "[119]\tvalidation_0-logloss:0.53825\n",
      "[120]\tvalidation_0-logloss:0.53823\n",
      "[121]\tvalidation_0-logloss:0.53822\n",
      "[122]\tvalidation_0-logloss:0.53800\n",
      "[123]\tvalidation_0-logloss:0.53794\n",
      "[124]\tvalidation_0-logloss:0.53769\n",
      "[125]\tvalidation_0-logloss:0.53760\n",
      "[126]\tvalidation_0-logloss:0.53750\n",
      "[127]\tvalidation_0-logloss:0.53723\n",
      "[128]\tvalidation_0-logloss:0.53667\n",
      "[129]\tvalidation_0-logloss:0.53660\n",
      "[130]\tvalidation_0-logloss:0.53659\n",
      "[131]\tvalidation_0-logloss:0.53658\n",
      "[132]\tvalidation_0-logloss:0.53652\n",
      "[133]\tvalidation_0-logloss:0.53624\n",
      "[134]\tvalidation_0-logloss:0.53606\n",
      "[135]\tvalidation_0-logloss:0.53588\n",
      "[136]\tvalidation_0-logloss:0.53588\n",
      "[137]\tvalidation_0-logloss:0.53586\n",
      "[138]\tvalidation_0-logloss:0.53582\n",
      "[139]\tvalidation_0-logloss:0.53582\n",
      "[140]\tvalidation_0-logloss:0.53582\n",
      "[141]\tvalidation_0-logloss:0.53581\n",
      "[142]\tvalidation_0-logloss:0.53575\n",
      "[143]\tvalidation_0-logloss:0.53574\n",
      "[144]\tvalidation_0-logloss:0.53530\n",
      "[145]\tvalidation_0-logloss:0.53516\n",
      "[146]\tvalidation_0-logloss:0.53499\n",
      "[147]\tvalidation_0-logloss:0.53482\n",
      "[148]\tvalidation_0-logloss:0.53479\n",
      "[149]\tvalidation_0-logloss:0.53473\n",
      "[150]\tvalidation_0-logloss:0.53453\n",
      "[151]\tvalidation_0-logloss:0.53452\n",
      "[152]\tvalidation_0-logloss:0.53451\n",
      "[153]\tvalidation_0-logloss:0.53453\n",
      "[154]\tvalidation_0-logloss:0.53452\n",
      "[155]\tvalidation_0-logloss:0.53451\n",
      "[156]\tvalidation_0-logloss:0.53448\n",
      "[157]\tvalidation_0-logloss:0.53438\n",
      "[158]\tvalidation_0-logloss:0.53426\n",
      "[159]\tvalidation_0-logloss:0.53418\n",
      "[160]\tvalidation_0-logloss:0.53418\n",
      "[161]\tvalidation_0-logloss:0.53418\n",
      "[162]\tvalidation_0-logloss:0.53419\n",
      "[163]\tvalidation_0-logloss:0.53408\n",
      "[164]\tvalidation_0-logloss:0.53405\n",
      "[165]\tvalidation_0-logloss:0.53406\n",
      "[166]\tvalidation_0-logloss:0.53406\n",
      "[167]\tvalidation_0-logloss:0.53406\n",
      "[168]\tvalidation_0-logloss:0.53404\n",
      "[169]\tvalidation_0-logloss:0.53405\n",
      "[170]\tvalidation_0-logloss:0.53406\n",
      "[171]\tvalidation_0-logloss:0.53407\n",
      "[172]\tvalidation_0-logloss:0.53405\n",
      "[173]\tvalidation_0-logloss:0.53403\n",
      "[174]\tvalidation_0-logloss:0.53380\n",
      "[175]\tvalidation_0-logloss:0.53361\n",
      "[176]\tvalidation_0-logloss:0.53344\n",
      "[177]\tvalidation_0-logloss:0.53314\n",
      "[178]\tvalidation_0-logloss:0.53313\n",
      "[179]\tvalidation_0-logloss:0.53312\n",
      "[180]\tvalidation_0-logloss:0.53311\n",
      "[181]\tvalidation_0-logloss:0.53309\n",
      "[182]\tvalidation_0-logloss:0.53288\n",
      "[183]\tvalidation_0-logloss:0.53268\n",
      "[184]\tvalidation_0-logloss:0.53263\n",
      "[185]\tvalidation_0-logloss:0.53264\n",
      "[186]\tvalidation_0-logloss:0.53264\n",
      "[187]\tvalidation_0-logloss:0.53265\n",
      "[188]\tvalidation_0-logloss:0.53262\n",
      "[189]\tvalidation_0-logloss:0.53262\n",
      "[190]\tvalidation_0-logloss:0.53258\n",
      "[191]\tvalidation_0-logloss:0.53259\n",
      "[192]\tvalidation_0-logloss:0.53258\n",
      "[193]\tvalidation_0-logloss:0.53259\n",
      "[194]\tvalidation_0-logloss:0.53259\n",
      "[195]\tvalidation_0-logloss:0.53259\n",
      "[196]\tvalidation_0-logloss:0.53260\n",
      "[197]\tvalidation_0-logloss:0.53259\n",
      "[198]\tvalidation_0-logloss:0.53257\n",
      "[199]\tvalidation_0-logloss:0.53255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yugik\\OneDrive - Singapore Institute Of Technology\\Y2 T2\\INF2008 MACHINE LEARNING\\Project\\ProjectTesting\\env\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:01:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost OOF Accuracy: 0.7298\n",
      "XGBoost Test Accuracy: 0.7347\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import gc \n",
    "import torch \n",
    " \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() # clear my vram\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 9,\n",
    "    'n_estimators': 200,\n",
    "    'gamma': 1.0, \n",
    "    'colsample_bytree': 1.0, \n",
    "    'subsample' : 1.0, \n",
    "    'enable_categorical': True ,\n",
    "    'tree_method': 'gpu_hist',\n",
    "\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds_xgb = np.zeros(X_train.shape[0])  # OOF storage\n",
    "test_preds_xgb = np.zeros(X_test.shape[0])  # Test storage\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold+1}/{n_folds}...\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    #  Train XGBoost model\n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=True  \n",
    "    )\n",
    "\n",
    "    #  Store OOF predictions\n",
    "    oof_preds_xgb[valid_idx] = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    #  Predict on test set and average across folds\n",
    "    test_preds_xgb += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "\n",
    "#  Evaluate XGBoost OOF Accuracy\n",
    "oof_accuracy_xgb = accuracy_score(y_train, (oof_preds_xgb > 0.5).astype(int))\n",
    "\n",
    "#  Evaluate XGBoost Test Accuracy\n",
    "test_preds_xgb_binary = (test_preds_xgb > 0.5).astype(int)\n",
    "test_accuracy_xgb = accuracy_score(y_test, test_preds_xgb_binary)\n",
    "\n",
    "\n",
    "print(f\"XGBoost OOF Accuracy: {oof_accuracy_xgb:.4f}\")\n",
    "print(f\"XGBoost Test Accuracy: {test_accuracy_xgb:.4f}\")  # ✅ Now showing test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATBOOST\n",
    "  \n",
    "GRID SEARCH WITH CATBOOST (Not Performed In this script) - task separated out for another team, but  the following params are used based on the best params found by them on gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Airline Code',\n",
       " 'Aircraft Registration',\n",
       " 'Operator',\n",
       " 'Type Code',\n",
       " 'Mode S',\n",
       " 'Serial Number',\n",
       " 'FROM',\n",
       " 'TO']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cat_cols].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n",
      "0:\tlearn: 0.6539931\ttest: 0.6531735\tbest: 0.6531735 (0)\ttotal: 6.51s\tremaining: 54m 9s\n",
      "50:\tlearn: 0.5415611\ttest: 0.5357743\tbest: 0.5357743 (50)\ttotal: 5m 17s\tremaining: 46m 31s\n",
      "100:\tlearn: 0.5318352\ttest: 0.5260291\tbest: 0.5260291 (100)\ttotal: 10m 41s\tremaining: 42m 16s\n",
      "150:\tlearn: 0.5269198\ttest: 0.5211274\tbest: 0.5211274 (150)\ttotal: 16m 3s\tremaining: 37m 5s\n",
      "200:\tlearn: 0.5230662\ttest: 0.5172855\tbest: 0.5172855 (200)\ttotal: 21m 23s\tremaining: 31m 49s\n",
      "250:\tlearn: 0.5202906\ttest: 0.5146718\tbest: 0.5146718 (250)\ttotal: 26m 40s\tremaining: 26m 28s\n",
      "300:\tlearn: 0.5177140\ttest: 0.5121850\tbest: 0.5121850 (300)\ttotal: 32m 14s\tremaining: 21m 18s\n",
      "350:\tlearn: 0.5155545\ttest: 0.5100991\tbest: 0.5100991 (350)\ttotal: 38m 30s\tremaining: 16m 20s\n",
      "400:\tlearn: 0.5136194\ttest: 0.5082721\tbest: 0.5082721 (400)\ttotal: 44m 28s\tremaining: 10m 58s\n",
      "450:\tlearn: 0.5121611\ttest: 0.5070455\tbest: 0.5070455 (450)\ttotal: 50m 19s\tremaining: 5m 28s\n",
      "499:\tlearn: 0.5107110\ttest: 0.5057485\tbest: 0.5057485 (499)\ttotal: 56m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5057485358\n",
      "bestIteration = 499\n",
      "\n",
      "Training fold 2/5...\n",
      "0:\tlearn: 0.6539553\ttest: 0.6525866\tbest: 0.6525866 (0)\ttotal: 5.81s\tremaining: 48m 17s\n",
      "50:\tlearn: 0.5429262\ttest: 0.5370751\tbest: 0.5370751 (50)\ttotal: 5m 39s\tremaining: 49m 46s\n",
      "100:\tlearn: 0.5336073\ttest: 0.5276431\tbest: 0.5276431 (100)\ttotal: 11m 43s\tremaining: 46m 20s\n",
      "150:\tlearn: 0.5278682\ttest: 0.5218092\tbest: 0.5218092 (150)\ttotal: 17m 25s\tremaining: 40m 16s\n",
      "200:\tlearn: 0.5240754\ttest: 0.5180817\tbest: 0.5180817 (200)\ttotal: 23m 18s\tremaining: 34m 39s\n",
      "250:\tlearn: 0.5211988\ttest: 0.5153042\tbest: 0.5153042 (250)\ttotal: 29m 3s\tremaining: 28m 49s\n",
      "300:\tlearn: 0.5183696\ttest: 0.5125128\tbest: 0.5125128 (300)\ttotal: 35m 37s\tremaining: 23m 33s\n",
      "350:\tlearn: 0.5161950\ttest: 0.5104134\tbest: 0.5104134 (350)\ttotal: 41m 41s\tremaining: 17m 41s\n",
      "400:\tlearn: 0.5143358\ttest: 0.5086658\tbest: 0.5086658 (400)\ttotal: 47m 39s\tremaining: 11m 45s\n",
      "450:\tlearn: 0.5125263\ttest: 0.5069203\tbest: 0.5069203 (450)\ttotal: 53m 35s\tremaining: 5m 49s\n",
      "499:\tlearn: 0.5110026\ttest: 0.5054887\tbest: 0.5054887 (499)\ttotal: 59m 37s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5054887252\n",
      "bestIteration = 499\n",
      "\n",
      "Training fold 3/5...\n",
      "0:\tlearn: 0.6537843\ttest: 0.6524386\tbest: 0.6524386 (0)\ttotal: 6.41s\tremaining: 53m 20s\n",
      "50:\tlearn: 0.5419334\ttest: 0.5358299\tbest: 0.5358299 (50)\ttotal: 5m 59s\tremaining: 52m 46s\n",
      "100:\tlearn: 0.5323181\ttest: 0.5259620\tbest: 0.5259620 (100)\ttotal: 11m 58s\tremaining: 47m 19s\n",
      "150:\tlearn: 0.5276777\ttest: 0.5213224\tbest: 0.5213224 (150)\ttotal: 17m 51s\tremaining: 41m 17s\n",
      "200:\tlearn: 0.5239152\ttest: 0.5176361\tbest: 0.5176361 (200)\ttotal: 23m 43s\tremaining: 35m 18s\n",
      "250:\tlearn: 0.5210113\ttest: 0.5148090\tbest: 0.5148090 (250)\ttotal: 29m 24s\tremaining: 29m 10s\n",
      "300:\tlearn: 0.5185094\ttest: 0.5124098\tbest: 0.5124098 (300)\ttotal: 34m 40s\tremaining: 22m 55s\n",
      "350:\tlearn: 0.5163972\ttest: 0.5104251\tbest: 0.5104251 (350)\ttotal: 40m 10s\tremaining: 17m 3s\n",
      "400:\tlearn: 0.5144436\ttest: 0.5085995\tbest: 0.5085995 (400)\ttotal: 45m 40s\tremaining: 11m 16s\n",
      "450:\tlearn: 0.5127352\ttest: 0.5070132\tbest: 0.5070132 (450)\ttotal: 51m 4s\tremaining: 5m 32s\n",
      "499:\tlearn: 0.5114044\ttest: 0.5058642\tbest: 0.5058642 (499)\ttotal: 56m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.505864192\n",
      "bestIteration = 499\n",
      "\n",
      "Training fold 4/5...\n",
      "0:\tlearn: 0.6539595\ttest: 0.6526424\tbest: 0.6526424 (0)\ttotal: 5.92s\tremaining: 49m 13s\n",
      "50:\tlearn: 0.5424996\ttest: 0.5364530\tbest: 0.5364530 (50)\ttotal: 5m 41s\tremaining: 50m 6s\n",
      "100:\tlearn: 0.5330653\ttest: 0.5267636\tbest: 0.5267636 (100)\ttotal: 11m 8s\tremaining: 44m 2s\n",
      "150:\tlearn: 0.5275013\ttest: 0.5211146\tbest: 0.5211146 (150)\ttotal: 16m 47s\tremaining: 38m 49s\n",
      "200:\tlearn: 0.5235673\ttest: 0.5172615\tbest: 0.5172615 (200)\ttotal: 22m 18s\tremaining: 33m 10s\n",
      "250:\tlearn: 0.5207598\ttest: 0.5146067\tbest: 0.5146067 (250)\ttotal: 27m 50s\tremaining: 27m 36s\n",
      "300:\tlearn: 0.5182232\ttest: 0.5121873\tbest: 0.5121873 (300)\ttotal: 33m 22s\tremaining: 22m 3s\n",
      "350:\tlearn: 0.5162461\ttest: 0.5103731\tbest: 0.5103731 (350)\ttotal: 39m 3s\tremaining: 16m 34s\n",
      "400:\tlearn: 0.5143411\ttest: 0.5085757\tbest: 0.5085757 (400)\ttotal: 44m 51s\tremaining: 11m 4s\n",
      "450:\tlearn: 0.5128597\ttest: 0.5072610\tbest: 0.5072610 (450)\ttotal: 50m 24s\tremaining: 5m 28s\n",
      "499:\tlearn: 0.5113884\ttest: 0.5059156\tbest: 0.5059156 (499)\ttotal: 56m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5059156147\n",
      "bestIteration = 499\n",
      "\n",
      "Training fold 5/5...\n",
      "0:\tlearn: 0.6540011\ttest: 0.6531947\tbest: 0.6531947 (0)\ttotal: 7.08s\tremaining: 58m 53s\n",
      "50:\tlearn: 0.5419152\ttest: 0.5365948\tbest: 0.5365948 (50)\ttotal: 6m\tremaining: 52m 49s\n",
      "100:\tlearn: 0.5323064\ttest: 0.5266348\tbest: 0.5266348 (100)\ttotal: 12m 6s\tremaining: 47m 51s\n",
      "150:\tlearn: 0.5273579\ttest: 0.5216897\tbest: 0.5216897 (150)\ttotal: 18m 8s\tremaining: 41m 55s\n",
      "200:\tlearn: 0.5233544\ttest: 0.5176751\tbest: 0.5176751 (200)\ttotal: 24m 12s\tremaining: 36m\n",
      "250:\tlearn: 0.5206067\ttest: 0.5149788\tbest: 0.5149788 (250)\ttotal: 30m 4s\tremaining: 29m 49s\n",
      "300:\tlearn: 0.5178881\ttest: 0.5122949\tbest: 0.5122949 (300)\ttotal: 35m 44s\tremaining: 23m 38s\n",
      "350:\tlearn: 0.5159249\ttest: 0.5104588\tbest: 0.5104588 (350)\ttotal: 41m 41s\tremaining: 17m 42s\n",
      "400:\tlearn: 0.5140165\ttest: 0.5086771\tbest: 0.5086771 (400)\ttotal: 47m 35s\tremaining: 11m 45s\n",
      "450:\tlearn: 0.5123312\ttest: 0.5070840\tbest: 0.5070840 (450)\ttotal: 53m 32s\tremaining: 5m 49s\n",
      "499:\tlearn: 0.5108667\ttest: 0.5057566\tbest: 0.5057566 (499)\ttotal: 59m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5057566262\n",
      "bestIteration = 499\n",
      "\n",
      "CatBoost OOF Accuracy: 0.7492\n",
      "CatBoost Test Accuracy: 0.7515\n"
     ]
    }
   ],
   "source": [
    "cat_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'learning_rate': 0.2,\n",
    "    'depth': 8,                   # Reduced depth for faster training\n",
    "    'iterations': 500,            # Further reduced iterations\n",
    "    'colsample_bylevel': 1.0,\n",
    "    'random_strength': 0,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'task_type': 'CPU',\n",
    "    'verbose': 50,\n",
    "    'allow_writing_files': False,\n",
    "    'thread_count': 4,\n",
    "    'early_stopping_rounds': 30   # Adjust early stopping rounds if needed\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds_cat = np.zeros(X_train.shape[0])\n",
    "test_preds_cat = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold+1}/{n_folds}...\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # Create CatBoost model\n",
    "    model_cat = CatBoostClassifier(**cat_params)\n",
    "    model_cat.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=(X_val, y_val),\n",
    "        cat_features=X_train[cat_cols].columns.tolist(),\n",
    "        use_best_model=True  # Early stopping if it doesn't improve\n",
    "    )\n",
    "\n",
    "    # OOF predictions\n",
    "    oof_preds_cat[valid_idx] = model_cat.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Test predictions\n",
    "    test_preds_cat += model_cat.predict_proba(X_test)[:, 1] / n_folds\n",
    "\n",
    "# Evaluate CatBoost OOF Accuracy\n",
    "oof_accuracy_cat = accuracy_score(y_train, (oof_preds_cat > 0.5).astype(int))\n",
    "\n",
    "# Evaluate CatBoost Test Accuracy\n",
    "test_preds_cat_binary = (test_preds_cat > 0.5).astype(int)\n",
    "test_accuracy_cat = accuracy_score(y_test, test_preds_cat_binary)\n",
    "\n",
    "print(f\"CatBoost OOF Accuracy: {oof_accuracy_cat:.4f}\")\n",
    "print(f\"CatBoost Test Accuracy: {test_accuracy_cat:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STACK THIS UP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacked Model Test Accuracy (Logistic Regression): 0.7516\n",
      "Confusion Matrix:\n",
      "[[1263176  199388]\n",
      " [ 380442  490952]]\n",
      "F1 Score: 0.6287\n",
      "Precision: 0.7112\n",
      "Recall: 0.5634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Combine OOF predictions from all base models\n",
    "meta_X_train = np.column_stack((oof_preds_xgb, oof_preds_lgb, oof_preds_cat))\n",
    "meta_y_train = y_train  # target remains the same\n",
    "\n",
    "# Train Logistic Regression Meta-Model\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(meta_X_train, meta_y_train)\n",
    "\n",
    "# Combine Test Predictions for Final Prediction\n",
    "meta_X_test = np.column_stack((test_preds_xgb, test_preds_lgb, test_preds_cat))\n",
    "final_test_preds = meta_model.predict(meta_X_test)  # Predict final test labels\n",
    "\n",
    "# Evaluate Meta-Model Performance\n",
    "final_accuracy = accuracy_score(y_test, final_test_preds)\n",
    "cm = confusion_matrix(y_test, final_test_preds)\n",
    "f1 = f1_score(y_test, final_test_preds)\n",
    "precision = precision_score(y_test, final_test_preds)\n",
    "recall = recall_score(y_test, final_test_preds)\n",
    "\n",
    "print(f\"Final Stacked Model Test Accuracy (Logistic Regression): {final_accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacked Model Test Accuracy (SGDClassifier): 0.7514\n",
      "Confusion Matrix:\n",
      "[[1266665  195899]\n",
      " [ 384426  486968]]\n",
      "F1 Score: 0.6266\n",
      "Precision: 0.7131\n",
      "Recall: 0.5588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Combine OOF predictions from all base models\n",
    "meta_X_train = np.column_stack((oof_preds_xgb, oof_preds_lgb, oof_preds_cat))\n",
    "meta_y_train = y_train  # target remains the same\n",
    "\n",
    "# Train SGDClassifier as Meta-Model with logistic regression loss\n",
    "meta_model = SGDClassifier(loss=\"log_loss\", max_iter=1000, tol=1e-3, random_state=42)\n",
    "meta_model.fit(meta_X_train, meta_y_train)\n",
    "\n",
    "# Combine Test Predictions for Final Prediction\n",
    "meta_X_test = np.column_stack((test_preds_xgb, test_preds_lgb, test_preds_cat))\n",
    "final_test_preds = meta_model.predict(meta_X_test)  # Predict final test labels\n",
    "\n",
    "# Evaluate Meta-Model Performance\n",
    "final_accuracy = accuracy_score(y_test, final_test_preds)\n",
    "cm = confusion_matrix(y_test, final_test_preds)\n",
    "f1 = f1_score(y_test, final_test_preds)\n",
    "precision = precision_score(y_test, final_test_preds)\n",
    "recall = recall_score(y_test, final_test_preds)\n",
    "\n",
    "print(f\"Final Stacked Model Test Accuracy (SGDClassifier): {final_accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
